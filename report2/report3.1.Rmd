---
title: "Restauration d'image grâce aux chaînes de markov"
author: "Clément Thion"
date: "06/2020"
output:
  html_document:
    df_print: paged
  pdf_document: default
---



# Introduction

L'objectif final de ce stage est de restaurer algorithmiquement des images binaires (assez simples) en noir et blanc ayant subi un bruitage. Pour cela on utilise les chaînes de Markov et des modèles énergétiques sur les images, principalement le modèle d'Ising et la mesure de Gibbs, afin de pouvoir estimer de manière probabiliste les meilleures configurations pour la restauration. Les algorithmes ainsi constitués sont ensuite codés en R pour être testés.    

Dans dans son état actuel, ce rapport abborde plusieurs question en lien avec le sujet mais est très loin d'être complet. Une grande part des observations sont encore d'ordre empirique et nécessiteraient d'être approfondies sur le plan théorique. Pour autant on dispose déjà de plusieurs algorithmes fonctionnels permettant une restauration satisfaisante d'images simples.

## Modélisation d'une image

Afin de pouvoir manipuler des images, on utilise les notations et appellations suivantes:  
- x : une configuration d'une grille de pixels donnée (une image donc), parmis l'ensemble des configurations possibles $\Omega$. On note X la variable aléatoire décrivant x.   
- s : un pixel de l'image (on appelle aussi les pixels des "sites"), avec $x_s$ sa valeur. $x_s\in E$ l'ensemble des valeurs possibles possibles d'un pixel. E varie selon le type d'image (couleur, noir et blanc). Pour faciliter le travail, on ne manipule ici que des images en noir et blanc, donc $E=\{-1,1\}$.On note $X_s$ la variable aléatoire décrivant les différents états de $x_s$.  
- $X^s$ :la variable aléatoire décrivant la configuration de l'image privée du pixel $s$. $x^s$ est donc une fonfiguration x donnée, privée de s.  
- $V_s$ : le voisinage de s, que l'on définira plus tard.
- $U$ : le potentiel d'un pixel ou d'une image dans une configuration donnée, appelé aussi énergie.

## Le modèle d'Ising

Afin de calculer des probabilités sur les configurations possibles, on introduit la notion de potentiel U. Le potentiel d'une configuration de pixels, que ce soit l'image en entier ou localement un pixel de l'image et son voisinage, c'est une valeur numérique qui dépend des valeurs des pixels de la configuration.

Il existe plusieurs modèle pour le calculer, et celui que l'on utilisera est le modèle d'Ising.

\[U(x_s) = -\beta x_s \sum_{t\in V_s}{x_t} -B\sum_{s\in S}{x_s}\]

Littéralement, le potentiel de s quand $X=x_s$ est la somme de la valeur des états de ses voisins multiplié par un facteur $-\beta$, plus la somme des valeurs de tous les sites de l'image multiplié par un facteur $-B$.

On remarquera par la suite que le plus important ce sont les signes des facteurs, et non leur valeur absolue. En effet, un $\beta < 0$ donnera $U(x_s)$ positif pour le cas où $x_s$ est globalement opposé à $V_s$, et vice versa pour $\beta > 0$.  
Le terme $-B\sum_{s\in S}{x_s}$ quant à lui n'a pas parru nécessaire pour le cas particulier de la restauration d'image, au vu de nos propre test et de la littérature sur le sujet. C'est pourquoi dans la majorité des algorithmes qui suivront, il est mis à zero.

## La mesure de Gibbs 

Maintenant, comment utiliser ce calcul de potentiel local pour calculer les probabilités qui nous interessent ? Considérons une image bruitée; la première idée qu'il vient pour retrouver la bonne image est d'essayer une par une toutes les configurations de $\Omega$, mais ce n'est pas envisageable devant son cardinal. Rien que pour une image en noir et blanc on part déjà sur des puissances de deux, une petite image de sept cent vingt pixels aura $2^720$ configurations différentes...

Pour autant, si on voulait essayer, il existe un  outil, la mesure de Gibbs, qui permet justement de calculer la probabilité $P(X=x)$.

\[P(X=x)=\frac{1}{Z}e^{-U(x)}\].  

Cependant \[Z=\sum_{x\in \Omega}e^{-U(x)}\] représente une somme beaucoup trop grande pour être calculer en pratique, justement à cause de la taille de $\Omega$.

## L'hypothèse markovienne

Pour pallier au problème, une autre approche aussi intuitive pour restaurer cette image consiste à restaurer chaque pixel de l'image un par un, plutôt que considérer l'image dans son ensemble directement.  

A priori pour "deviner" quelle est la bonne valeur pour un pixel s, le mieux à faire est de regarder tous le reste de l'image $x^s$, et à partir de $x^s$ essayer d'exprimer $X_s$ pour trouver quelle valeur $x_s$ est la plus probable sachant $x^s$. Cependant, on fait l'hypothèse que connaître $V_s$ le voisinage proche de s est équivalent à connaître $x^s$, soit $P(X_s=x_s| X^s) = P(X_s=x_s|V_s)$. C'est l'hypothèse de Markov, et elle est assez naturelle quand on observe une image; un pixel blanc isolé avec autour de lui seulement des pixels rouges est une situation assez rare, les différentes parties de couleur uniforme d'une images étant souvent grande de plusieurs pixels, d'autant plus pour une image en noir et blanc dépourvue de dégradé. Faire l'hypothèse de Markov ne semble donc pas à priori ridicul. Et c'est grâce à cette hypothèse que l'on va pouvoir utiliser le modèle d'Ising pour le calcul de potentiel local.

La définition du voisinage de s peut varier, par son étendu et sa forme; le voisinage que nous utiliserons presque toujours est simplement l'ensemble des quatre plus proches voisins de s sur la verticale et l'horizontale. On essaira par la suite de modifier ce voisinage.



OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO
OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO
OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO

## La mesure de Gibbs locale


On sait la chose suivante:  
\[P(X_s=x_s)=\frac{1}{Z}e^{-U(x_s)}\]
\[P(X=x)=\frac{1}{Z}e^{-U(x)}\]  
Avec \[Z=\sum_{x\in \Omega}e^{-U(x)}\] la fonction de partition.  


OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO
OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO
OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO


## Adapation à la restauration d'image

Pour la restaurer une image, on comprend qu'il manque quelque chose au modèle d'Ising. Tel qu'il est, l'image bruitée initiale n'entre pas en ligne de compte pour le calcul du pententiel locale. Et étant donnée que c'est la configuration de plus basse énergie qui est la plus probable, avec ce modèle toute image bruitée devrait logiquement être restaurée en une l'image blanche ou un damier de pixel, qui sont bien les configurations de plus basse énergie selon le signe de $\beta$. Il faut donc ajouter un terme au modèle d'Ising pour que l'image bruitée initiale entre en ligne de compte. On pose: $ U(x_s) = -\beta x_s \sum_{t\in V_s}{x_t} -B\sum_{s\in S}{x_s} -\alpha x_s^0$ avec $x_s^0$ la valeur du site s de l'image bruitée initiale, et $\alpha$ le facteur qui déterminera le poid que l'on accord à la configuration initiale.

# Des algorithmes pour la restauration d'image: Gibbs et Metropolis

Pour restaurer des images à l'aide des outils que l'on a vu, on peut utiliser les algorithmes de Metropolis ou de Gibbs. On présente les deux:  

### L'algorithme de métropolis

**étape 1** On choisit un site s de l'image. La façon de choisir est libre du moment que l'on est assuré de parcourir tous les sites de l'image.  
**étape 2** On tire au hasard une nouvelle valeur $\lambda$ dans $E$ privé de $x_s^0$  
**étape 3** On calcule les potentiels $U(x_s)$ et $U(\lambda)$  
**étape 4** On calcule le rapport $P(X_s=x_s)/P(X_s=\lambda)=exp(U(x_s)-U(\lambda))$
**étape 5** On tire un nombre entre zero et un pour simuler la loi. S'il est inférieur au rapport de Metropolis, on refuse le changement; s'il est supérieur ou égale on l'accept.

## Boite à outils

Pour faciliter la manipulation des algorithmes, on crée quelques fonctions utiles.  
- bruiteur() prend une image en argument et la retourne bruitée de la manière souhaitée. Pour l'instant on n'a étudié qu'un bruit consistant en une inversion de valeur des pixels avec la probabilité donnée en argument (souvent $p=0.3$). À l'avenir on pourra tester les performances de nos algorithmes pour des bruits différents  
- imageGenerator() regroupe les différentes images que l'on bruitera avec bruiteur() pour ensuite essayer de les restaurer.  
  
L'avantage d'utiliser des fonctions est que l'on pourra facilement ajouter de nouvelles valeurs pour effectuer des tests, sans avoir à modifier les algorithmes directement. 

```{r boiteOutils}
bruiteur=function(image, br, p){
  
  imgBr <- image #future image bruitée
  N <- dim(image)[1] #longueur de l'image
  bruit <- 0
  p <- 0.15
  #----binomiale----
  if(br== "rbinom"){bruit <- matrix(2*rbinom(N^2,1,1-p)-1,nrow=N,ncol=N)}
  
  #----poisson----
  
  #----normale----
  
  imgBr <- image*bruit
  return(imgBr)
}#func



imageGenerator=function(forme, N){
  #fonction permettant de générer une matrice-image de forme choisie, et de taille N*N
  
  img <- matrix(-1, nrow= N, ncol= N)
  
  #----rectangle----
  if(forme== "rectangle"){
    img[(N/4):(N*3/4),(N/4):(N*3/4)] <- 1}
  
  #----losange----
  if(forme== "losange"){
    for (i in 1:N){
      for (j in 1:N){
        img[i,j]=-1+2*(abs(i-j)<=N/4)*(abs(i+j-N)<=N/4)  
      }}#for#for
  }#if
  
  #----bandes verticales----
  if(forme=="bande"){
    for (j in 1:(N/2)){ img[,2*j]=rep(1,N) }
  }#if
  
  return(img)
}#func



```

Deux algorithmes existent pour simuler un champ de Markov.

## L'échantilloneur de Gibbs


```{r A_1_gibbsIsing}
#algo de GibbsIsing
#voisinage à la main
#pas de correspondance


```


## L'algorithme de Metropolis


L'algorithme que l'on va principalement utiliser pour la restauration d'image s'appelle l'algorithme de Metropolis.

A l'itération n:  
1 -  tirage d'un site, aléatoirement ou non, l'important étant que tous les sites puissent être visités. Pour la suite on choisira majoritairement un parcours aléatoire de l'image suivant une loi uniforme sur le nombre de pixels, mais on pourra aussi choisir un parcours systématisé ligne par ligne.  
2 -  tirage d'un état $\lambda$ de E différent de $x_s$ l'état actuel du site tiré. Dans notre cas $E=\{-1, 1\}$, donc on choisira systématiquement le complémentaire de $x_s$ dans E.  
3 -  calcul des deux potentiels $U(x_s)$ et $U(\lambda)$, pour la valeur actuelle de $x_s$ et pour la valeur tirée, donc ici systématiquement $U(-1)$ et $U(1)$.  
4 -  calcul de la probabilité $P(x_s=\lambda) = e^{U(\lambda)-U(x_s)}$.  
5 -  tirage aléatoire selon la loi uniforme sur $[0,1]$. Si le tirage est inférieure à la probabilité précédemment calculée,$x_s$ prend la valeur $\lambda$, sinon $x_s$ reste inchangé.  

En R voici une manière de coder cet algorithme :

```{r A_2_metropolisIsing_BASIQUE}
#BASIQUE
#tirage == aléatoire
#voisinage == à la main
#correspondance ==  SANS
```

> **Le paramètre alpha** détermine l'importance donnée à l'image bruitée initiale dans la probabilité conditionnelle $P(X_s=x_s|V_s)$.  
- Si alpha est trop grand devant $\beta$, les valeurs les plus probables seront toujours celles de l'image bruitée, et donc l'algorithme ne fera rien.

metropolisIsing avec $\alpha = 5$ et $\beta = 1$

```{r alpha_grand, echo=FALSE}
#metropolisIsing("rectangle", 64, 1, 0, 5, 10^5, 0.3)
```


> S'il est trop petit voir nul, la configuration initiale va être oubliée itération après itération, et on va tendre vers l'image blanche, soit donc la configuration d'énergie minimale parmi toutes les configurations possibles. 

metropolisIsing avec $\alpha = 0$

```{r alpha_nul, echo=FALSE}
#metropolisIsing("rectangle", 64, 1, 0, 0, 2*10^5, 0.3)
```


> **Le paramètre $\beta$** quant à lui détermine quel motifs seront les plus probables, entre des pixels de mêmes valeurs ($\beta > 0$) ou bien une alternance de pixel banc et noir ($\beta < 0$).


metropolisIsing avec $\beta > 0$
```{r, echo=FALSE}
#metropolisIsing("rectangle", 64, 1, 0, 0.6, 10^5, 0.3)
```


metropolisIsing avec $\beta < 0$
```{r, echo=FALSE}
#metropolisIsing("rectangle", 64, -1, 0, 0.6, 10^5, 0.3)
```


> **Le calcul du voisinage** se fait assez facilement en R, on regarde la valeur des quatre pixels à gauche à droit en haut et en bas du pixel. Plus tard on utilisera la fonction Vstar(), qui permet d'étendre ce voisinage.

> **Le parcours des sites_** peut se faire soit aléatoirement, soit systématiquement (ligne par ligne par exemple).


## Le recuit simulé

La question que l'on se pose: pourquoi modifier les paramètres à chaque itération permet de converger presque surement vers le minimum global d'énergie.

```{r recuitMetro}
#recuit Simulé perso, avec -dU/T 
```


```{r, echo=FALSE}
#recuitMetro("rectangle", 64, 1, 0, 0.6, 1, 2*10^4, 0.3)
```

On peut comparer les performances entre le recuit simulé et l'algorithme de Metropolis en comparant le pourcentage de restauration des deux algorithmes, à paramètres et image bruitée identique.

```{r}
#peut être afficher le code, mais on pourrait juste donner le résultat, et les images.

```


# Estimation du paramètre $\beta$

L'algorithme de recuit précédent marche plutôt bien pour des images pleines (rectangle, losange), mais si on éssaie de restaurer une image en plusieurs parties, une succession de bandes par exemple, ou un damier, l'algorithme ne fonctionne plus du tout. 

```{r}
#metropolisIsing("ligne", 64, 1, 0, 1, 10, 10^4, 0.15)

```


## Distinction des énergies verticales et horizontales

Une idée que l'on peut avoir pour palier au problème est de séparer les calcules de potentiels entre la verticale et l'horizontale, en appliquant à chaque terme un facteur beta dédié à une orientation, $\beta_h$ pour l'horizontale et $\beta_v$ pour la verticale. On a ainsi: $U(x_s)= -x_s[\beta_h(x_d+x_g)+\beta_v(x_h+x_b)+\alpha x_s^0]$ avec $x_d,x_g,x_h,x_b$ les valeurs des pixels voisins du site s respectivement à droite, gauche, haut, bas. On modifie l'algorithme de recuit pour essayer:

```{r}

```


On peut ainsi avoir des signes différents pour $\beta_h$ et $\beta_v$, et donc privilégier les lignes pour une direction et les alternances blanc/noir dans l'autre direction. Pour l'exemple précédent avec des lignes horizontales, on va choisir $\beta_h > 0$ pour privilégier les lignes sur l'horizontale et $\beta_v < 0$ pour privilégier l'alternance des pixels sur la verticale. CE N'EST PAS CA!!! CALCUL AUTOMATIQUE

```{r}
#algo qui va bien
```


## Voisinage de taille variable

Une autre manière de résoudre ce problème de restoration de bandes pourrait aussi se trouver dans l'étendue du voisinage. 

```{r}
#algo vbranche vstart
```

```{r}
#algo de recuit avec calcul de voisinage étendu et donc parametre L
```


REMARQUE A FAIRE QUAND MEME: en augmentant l'amplitude du voisinage comme on le fait là, on constate que la restauration des images est plus propre (confère au graphique que l'on avait fait, essayer de les remettre)

# Amélioration de la rapidité des algorithmes

Depuis le début, on fixe le nombre d'itérations de l'algorithme (souvent à $10^4$ ou $10^5$). Cependant, on peut supposer que parfois il ne soit pas nécessaire de faire autant d'itération pour arriver à un résultat correct. De plus, le bruitage est réalisé aléatoirement, et donc d'une exécution de d'algorithme à une autre, le nombre d'itérations nécessaires pour restaurer l'image ne sera pas forcément le même.  

Une manière de rendre le nombre d'itérations variable serait de le conditionner au nombre de parcours de site successifs sans changement de valeurs. On pourra ainsi déclarer arbitrairement que, dès que l'algorithme réalise dix itérations successives sans changement de valeur, il s'arrête. Le mieux serait de déterminer a priori, étant donnée l'image bruitée, le nombre minimal d'itérations successives sans modification à réaliser pour la restaurer à un certain pourcentage.  

C'est ce que l'on fait dans l'algorithme de recuit simulé suivant:

```{r nconsécutif}
#algo qui va bien
```

Pour aller encore plus vite, au lieu d'attendre dix itérations successives sans aucune modification, on pourrait arrêter l'algorithme dès que, au cours des dix dernières itérations, il y a eu plus 1 modification. On peut jouer sur ces deux paramètres (taille de la "fenêtre coulissante", ici 10, et nombre maximum de changements, 0 dans votre exemple, et ici 1).

```{r nminimum}
#algo modifié
```

  
# Evolution de la restauration en fonction d'un nombre d'itérations

Avec des algorithmes dont le nombre d'itération varie, on peut se demander quelle est la probabilité d'avoir une image restaurée à un H%, après n itérations consécutives sans changements.


Une première majoration très grossière peut être de considérer l'ensemble des images de plus hautes énergie, et de déterminer combien d'itération il faut au minimum pour les ramener à l'image blanche. Ce nombre sera forcément supérieur ou égale au nombre d'itérations nécessaires pour n'importe quel image donnée de même taille. 

## Probabilité d'avoir la configuration d'énergie minimale 

### Estimation du nombre de parcours minimum nécessaires à la restauration d'une image pour toute image donnée
Une première majoration très grossière peut se faire en passant l'image de départ à restaurer comme variable, pour laquelle nous n'avons à priori aucune informations. Peut importe l'image à restaurer, combien de parcours de site l'algorithme doit-il réaliser ?  

Pour un voisinage classique avec 4 voisins prenna valeur dans $\{-1,1\}$, on a $2^4=16$ configurations de voisinages possibles.  

L'avantage de notre approche, c'est qu'en l'absence d'information sur l'image à restaurer, on peut raisonnable considérer ces 16 configurations de voisinage comme équiprobables.

D'un point de vu énergétique, il n'y a que 5 cas possibles. $V_s\in\{-4,\ -2,\ 0,\ 2,\ 4\}$.


### Probabilité de succès pour un pixel
### Probabilité de succès pour une configuration complète

## Probabilité d'avoir restauré l'image à H%
