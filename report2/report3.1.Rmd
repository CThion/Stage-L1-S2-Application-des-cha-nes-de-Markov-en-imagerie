---
title: "Restauration d'image grâce aux chaînes de markov"
author: "Clément Thion"
date: "06/2020"
output:
  html_document:
    df_print: paged
  pdf_document: default
---



# Introduction

L'objectif final de ce stage est de restaurer algorithmiquement des images binaires (assez simples) en noir et blanc ayant subi un bruitage. Pour cela on utilise les chaînes de Markov et des modèles énergétiques sur les images, principalement le modèle d'Ising et la mesure de Gibbs, afin de pouvoir estimer de manière probabiliste les meilleurs configurations pour la restauration. Les algorithmes ainsi constitués sont ensuite codés en R pour être éprouvés.    

Dans dans son état actuel, ce rapport abborde plusieurs question en lien avec le sujet mais est très très loin d'être complet. Une grande part des observations sont encore d'ordre empirique et nécessiteraient d'être approfondies sur le plan théorique.

## Modélisation d'une image

Afin de pouvoir manipuler des images, on utilise les notations et appellations suivantes:  
- x : une configuration d'une grille de pixels donnée (une image donc), parmis l'ensemble des configurations possibles $\Omega$. On note X la variable aléatoire décrivant x.   
- s : un pixel de l'image (on appelle aussi les pixels des "sites"), avec $x_s$ sa valeur. $x_s\in E$ l'ensemble des valeurs possibles possibles d'un pixel. E varie selon le type d'image (couleur, noir et blanc). Pour faciliter le travail, on ne manipule ici que des images en noir et blanc, donc $E=\{-1,1\}$.On note $X_s$ la variable aléatoire décrivant $x_s$.  
- $X^s$ :la variable aléatoire décrivant la configuration de l'image privée du pixel $s$. $x^s$ est donc une fonfiguration x donnée, privée de s.  
- $V_s$ : le voisinage de s, que l'on définira plus tard.
- $U$ : le potentiel de x ou s, appelé aussi énergie, pour la valeur $x_s$.  

## Hypothèse markovienne 

Considérons une image bruitée; une approche intuitive pour restaurer cette image consiste à restaurer chaque pixel de l'image un par un. A priori pour "deviner" quelle est la bonne valeur pour un pixel s, le mieux à faire est de regarder tous le reste de l'image $x^s$, et à partir de $x^s$ essayer d'exprimer $X_s$ pour trouver quelle valeur $x_s$ est la plus probable sachant $x^s$.   

Etant donnée la taille des images aujourd'hui, à huit ou seize millions de pixels, l'idée ne parraît plus si bonne. Pour pallier au problème de la taille des images, on fait l'hypothèse que connaître $V_s$ le voisinage proche de s est équivalent à connaître $x^s$, soit $P(X_s=x_s| X^s) = P(X_s=x_s|V_s)$. C'est l'hypothèse de Markov.

La définition du voisinage proche peut varier, par son étendu et sa forme; le voisinage que nous utiliserons presque toujours est simplement l'ensemble des quatre plus proches voisins de s sur la verticale et l'horizontale. On essaira par la suite de modifier ce voisinage.






## La mesure de Gibbs

Pour calculer la probabilité qu'une configuration donnée corresponde à l'image restaurée $P(X=x)$, on va utiliser la mesure de Gibbs.

La mesure de Gibbs nous fournit une formule pour calculer, à partir du portentiel $U(x_s)$, la probabilité $P(X_s=x_s)$.

\[P(X_s=x_s)=\frac{1}{Z}e^{-U(x_s)}\]
\[P(X=x)=\frac{1}{Z}e^{-U(x)}\]  
Avec \[Z=\sum_{x\in \Omega}e^{-U(x)}\] la fonction de partition.


On voit ainsi que plus le potentiel d'un site pour une valeur donnée est grand, moins il est probable, et inversement.

## Potentiel d'un site: Le modèle d'Ising

Le modèle d'Ising nous fournit une formule pour calculer le potentiel d'un pixel, pour un état donné, en fonction de son voisinage. On a:

\[U(x_s) = -\beta x_s \sum_{t\in V_s}{x_t} -B\sum_{s\in S}{x_s}\]

C'est le paramètre $\beta$ qui détermine le poid accordé au voisinage, et B celui de la valeur de s.

On verra une de ses limites dans la partie sur l'estimation de $\beta$.



## Adapation à la restauration d'image

Ainsi avec le modèle d'Ising et la mesure de Gibbs, on pourrait essayer de restaurer une image en utilisant un algorithme de Montecarlo. En partant de l'image de départ, on réalise 

Pour la restauration d'image, on comprend qu'il manque quelque chose au modéle d'Ising. Tel qu'il est, avec un algorithme de metropolis, notre image tendrait irrémédiablement vers l'image blanche, qui est bien l'image de plus faible énergie dans l'absolu. Il nous faut passer à la probabilité conditionnée par la configuration de départ que l'on note $X^0$: $P(X_s=x_s|X^0,V_s)$. Pour se faire on ajoute un paramètre pour ternir compte de l'image bruitée de départ, de sorte que la configuration de plus basse énergie ne soit plus l'image blanche mais bien l'image que l'on souhaite restaurer. Ainsi on modifie $U(x_s)$ par:
\[ U(x_s) = -\beta x_s \sum_{t\in V_s}{x_t} -B\sum_{s\in S}{x_s} -\alpha x_s^0\]
avec $x_s^0$ la valeur du site s de l'image bruitée de départ.

# Des algorithmes pour la restauration d'image

## Boite à outils

Pour faciliter la manipulation des algorithmes, on crée quelques fonctions utiles.  
- bruiteur() prend une image en argument et la retourne bruitée de la manière souhaitée. Pour l'instant on n'a étudié qu'un bruit consistant en une inversion de valeur des pixels avec la probabilité donnée en argument (souvent $p=0.3$). À l'avenir on pourra tester les performances de nos algorithmes pour des bruits différents  
- imageGenerator() regroupe les différentes images que l'on bruitera avec bruiteur() pour ensuite essayer de les restaurer.  
  
L'avantage d'utiliser des fonctions est que l'on pourra facilement ajouter de nouvelles valeurs pour effectuer des tests, sans avoir à modifier les algorithmes directement. 

```{r boiteOutils}
bruiteur=function(image, br, p){
  
  imgBr <- image #future image bruitée
  N <- dim(image)[1] #longueur de l'image
  bruit <- 0
  p <- 0.15
  #----binomiale----
  if(br== "rbinom"){bruit <- matrix(2*rbinom(N^2,1,1-p)-1,nrow=N,ncol=N)}
  
  #----poisson----
  
  #----normale----
  
  imgBr <- image*bruit
  return(imgBr)
}#func



imageGenerator=function(forme, N){
  #fonction permettant de générer une matrice-image de forme choisie, et de taille N*N
  
  img <- matrix(-1, nrow= N, ncol= N)
  
  #----rectangle----
  if(forme== "rectangle"){
    img[(N/4):(N*3/4),(N/4):(N*3/4)] <- 1}
  
  #----losange----
  if(forme== "losange"){
    for (i in 1:N){
      for (j in 1:N){
        img[i,j]=-1+2*(abs(i-j)<=N/4)*(abs(i+j-N)<=N/4)  
      }}#for#for
  }#if
  
  #----bandes verticales----
  if(forme=="bande"){
    for (j in 1:(N/2)){ img[,2*j]=rep(1,N) }
  }#if
  
  return(img)
}#func



```

Deux algorithmes existent pour simuler un champ de Markov.

## L'échantilloneur de Gibbs


```{r A_1_gibbsIsing}
#algo de GibbsIsing
#voisinage à la main
#pas de correspondance


```


## L'algorithme de Metropolis


L'algorithme que l'on va principalement utiliser pour la restauration d'image s'appelle l'algorithme de Metropolis.

A l'itération n:  
1 -  tirage d'un site, aléatoirement ou non, l'important étant que tous les sites puissent être visités. Pour la suite on choisira majoritairement un parcours aléatoire de l'image suivant une loi uniforme sur le nombre de pixels, mais on pourra aussi choisir un parcours systématisé ligne par ligne.  
2 -  tirage d'un état $\lambda$ de E différent de $x_s$ l'état actuel du site tiré. Dans notre cas $E=\{-1, 1\}$, donc on choisira systématiquement le complémentaire de $x_s$ dans E.  
3 -  calcul des deux potentiels $U(x_s)$ et $U(\lambda)$, pour la valeur actuelle de $x_s$ et pour la valeur tirée, donc ici systématiquement $U(-1)$ et $U(1)$.  
4 -  calcul de la probabilité $P(x_s=\lambda) = e^{U(\lambda)-U(x_s)}$.  
5 -  tirage aléatoire selon la loi uniforme sur $[0,1]$. Si le tirage est inférieure à la probabilité précédemment calculée,$x_s$ prend la valeur $\lambda$, sinon $x_s$ reste inchangé.  

En R voici une manière de coder cet algorithme :

```{r A_2_metropolisIsing_BASIQUE}
#BASIQUE
#tirage == aléatoire
#voisinage == à la main
#correspondance ==  SANS
```

> **Le paramètre alpha** détermine l'importance donnée à l'image bruitée initiale dans la probabilité conditionnelle $P(X_s=x_s|V_s)$.  
- Si alpha est trop grand devant $\beta$, les valeurs les plus probables seront toujours celles de l'image bruitée, et donc l'algorithme ne fera rien.

metropolisIsing avec $\alpha = 5$ et $\beta = 1$

```{r alpha_grand, echo=FALSE}
#metropolisIsing("rectangle", 64, 1, 0, 5, 10^5, 0.3)
```


> S'il est trop petit voir nul, la configuration initiale va être oubliée itération après itération, et on va tendre vers l'image blanche, soit donc la configuration d'énergie minimale parmi toutes les configurations possibles. 

metropolisIsing avec $\alpha = 0$

```{r alpha_nul, echo=FALSE}
#metropolisIsing("rectangle", 64, 1, 0, 0, 2*10^5, 0.3)
```


> **Le paramètre $\beta$** quant à lui détermine quel motifs seront les plus probables, entre des pixels de mêmes valeurs ($\beta > 0$) ou bien une alternance de pixel banc et noir ($\beta < 0$).


metropolisIsing avec $\beta > 0$
```{r, echo=FALSE}
#metropolisIsing("rectangle", 64, 1, 0, 0.6, 10^5, 0.3)
```


metropolisIsing avec $\beta < 0$
```{r, echo=FALSE}
#metropolisIsing("rectangle", 64, -1, 0, 0.6, 10^5, 0.3)
```


> **Le calcul du voisinage** se fait assez facilement en R, on regarde la valeur des quatre pixels à gauche à droit en haut et en bas du pixel. Plus tard on utilisera la fonction Vstar(), qui permet d'étendre ce voisinage.

> **Le parcours des sites_** peut se faire soit aléatoirement, soit systématiquement (ligne par ligne par exemple).


## Le recuit simulé

La question que l'on se pose: pourquoi modifier les paramètres à chaque itération permet de converger presque surement vers le minimum global d'énergie.

```{r recuitMetro}
#recuit Simulé perso, avec -dU/T 
```


```{r, echo=FALSE}
#recuitMetro("rectangle", 64, 1, 0, 0.6, 1, 2*10^4, 0.3)
```

On peut comparer les performances entre le recuit simulé et l'algorithme de Metropolis en comparant le pourcentage de restauration des deux algorithmes, à paramètres et image bruitée identique.

```{r}
#peut être afficher le code, mais on pourrait juste donner le résultat, et les images.

```


# Estimation du paramètre $\beta$

L'algorithme de recuit précédent marche plutôt bien pour des images pleines (rectangle, losange), mais si on éssaie de restaurer une image en plusieurs parties, une succession de bandes par exemple, ou un damier, l'algorithme ne fonctionne plus du tout. 

```{r}
#metropolisIsing("ligne", 64, 1, 0, 1, 10, 10^4, 0.15)

```


## Distinction des énergies verticales et horizontales

Une idée que l'on peut avoir pour palier au problème est de séparer les calcules de potentiels entre la verticale et l'horizontale, en appliquant à chaque terme un facteur beta dédié à une orientation, $\beta_h$ pour l'horizontale et $\beta_v$ pour la verticale. On a ainsi: $U(x_s)= -x_s[\beta_h(x_d+x_g)+\beta_v(x_h+x_b)+\alpha x_s^0]$ avec $x_d,x_g,x_h,x_b$ les valeurs des pixels voisins du site s respectivement à droite, gauche, haut, bas. On modifie l'algorithme de recuit pour essayer:

```{r}

```


On peut ainsi avoir des signes différents pour $\beta_h$ et $\beta_v$, et donc privilégier les lignes pour une direction et les alternances blanc/noir dans l'autre direction. Pour l'exemple précédent avec des lignes horizontales, on va choisir $\beta_h > 0$ pour privilégier les lignes sur l'horizontale et $\beta_v < 0$ pour privilégier l'alternance des pixels sur la verticale. CE N'EST PAS CA!!! CALCUL AUTOMATIQUE

```{r}
#algo qui va bien
```


## Voisinage de taille variable

Une autre manière de résoudre ce problème de restoration de bandes pourrait aussi se trouver dans l'étendue du voisinage. 

```{r}
#algo vbranche vstart
```

```{r}
#algo de recuit avec calcul de voisinage étendu et donc parametre L
```


REMARQUE A FAIRE QUAND MEME: en augmentant l'amplitude du voisinage comme on le fait là, on constate que la restauration des images est plus propre (confère au graphique que l'on avait fait, essayer de les remettre)

# Amélioration de la rapidité des algorithmes

Depuis le début, on fixe le nombre d'itérations de l'algorithme (souvent à $10^4$ ou $10^5$). Cependant, on peut supposer que parfois il ne soit pas nécessaire de faire autant d'itération pour arriver à un résultat correct. De plus, le bruitage est réalisé aléatoirement, et donc d'une exécution de d'algorithme à une autre, le nombre d'itérations nécessaires pour restaurer l'image ne sera pas forcément le même.  

Une manière de rendre le nombre d'itérations variable serait de le conditionner au nombre de parcours de site successifs sans changement de valeurs. On pourra ainsi déclarer arbitrairement que, dès que l'algorithme réalise dix itérations successives sans changement de valeur, il s'arrête. Le mieux serait de déterminer a priori, étant donnée l'image bruitée, le nombre minimal d'itérations successives sans modification à réaliser pour la restaurer à un certain pourcentage.  

C'est ce que l'on fait dans l'algorithme de recuit simulé suivant:

```{r nconsécutif}
#algo qui va bien
```

Pour aller encore plus vite, au lieu d'attendre dix itérations successives sans aucune modification, on pourrait arrêter l'algorithme dès que, au cours des dix dernières itérations, il y a eu plus 1 modification. On peut jouer sur ces deux paramètres (taille de la "fenêtre coulissante", ici 10, et nombre maximum de changements, 0 dans votre exemple, et ici 1).

```{r nminimum}
#algo modifié
```

  
# Evolution de la restauration en fonction d'un nombre d'itérations

Avec des algorithmes dont le nombre d'itération varie, on peut se demander quelle est la probabilité d'avoir une image restaurée à un H%, après n itérations consécutives sans changements.


Une première majoration très grossière peut être de considérer l'ensemble des images de plus hautes énergie, et de déterminer combien d'itération il faut au minimum pour les ramener à l'image blanche. Ce nombre sera forcément supérieur ou égale au nombre d'itérations nécessaires pour n'importe quel image donnée de même taille. 

## Probabilité d'avoir la configuration d'énergie minimale 

### Estimation du nombre de parcours minimum nécessaires à la restauration d'une image pour toute image donnée
Une première majoration très grossière peut se faire en passant l'image de départ à restaurer comme variable, pour laquelle nous n'avons à priori aucune informations. Peut importe l'image à restaurer, combien de parcours de site l'algorithme doit-il réaliser ?  

Pour un voisinage classique avec 4 voisins prenna valeur dans $\{-1,1\}$, on a $2^4=16$ configurations de voisinages possibles.  

L'avantage de notre approche, c'est qu'en l'absence d'information sur l'image à restaurer, on peut raisonnable considérer ces 16 configurations de voisinage comme équiprobables.

D'un point de vu énergétique, il n'y a que 5 cas possibles. $V_s\in\{-4,\ -2,\ 0,\ 2,\ 4\}$.


### Probabilité de succès pour un pixel
### Probabilité de succès pour une configuration complète

## Probabilité d'avoir restauré l'image à H%
