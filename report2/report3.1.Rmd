---
title: "Restauration d'image grâce aux chaînes de markov"
author: "Clément Thion"
date: "06/2020"
output:
  html_document:
    df_print: paged
  pdf_document: default
---



# Introduction

L'objectif final de ce stage est de restaurer algorithmiquement des images binaires (assez simples) en noir et blanc ayant subi un bruitage. Pour cela on utilise les chaînes de Markov et des modèles énergétiques sur les images, principalement le modèle d'Ising et la mesure de Gibbs, afin de pouvoir estimer de manière probabiliste les meilleures configurations pour la restauration. Les algorithmes ainsi constitués sont ensuite codés en R pour être testés.    

Dans dans son état actuel, ce rapport abborde plusieurs question en lien avec le sujet mais est très loin d'être complet. Une grande part des observations sont encore d'ordre empirique et nécessiteraient d'être approfondies sur le plan théorique. Pour autant on dispose déjà de plusieurs algorithmes fonctionnels permettant une restauration satisfaisante d'images simples.

## Modélisation d'une image

Afin de pouvoir manipuler des images, on utilise les notations et appellations suivantes:  
- x : une configuration d'une grille de pixels donnée (une image donc), parmis l'ensemble des configurations possibles $\Omega$. On note X la variable aléatoire décrivant x.   
- s : un pixel de l'image (on appelle aussi les pixels des "sites"), avec $x_s$ sa valeur. $x_s\in E$ l'ensemble des valeurs possibles possibles d'un pixel. E varie selon le type d'image (couleur, noir et blanc). Pour faciliter le travail, on ne manipule ici que des images en noir et blanc, donc $E=\{-1,1\}$.On note $X_s$ la variable aléatoire décrivant les différents états de $x_s$.  
- $X^s$ :la variable aléatoire décrivant la configuration de l'image privée du pixel $s$. $x^s$ est donc une fonfiguration x donnée, privée de s.  
- $V_s$ : le voisinage de s, que l'on définira plus tard.
- $U$ : le potentiel d'un pixel ou d'une image dans une configuration donnée, appelé aussi énergie.

## Le modèle d'Ising

Afin de calculer des probabilités sur les configurations possibles, on introduit la notion de potentiel U. Le potentiel d'une configuration de pixels, que ce soit l'image en entier ou localement un pixel de l'image et son voisinage, c'est une valeur numérique qui dépend des valeurs des pixels de la configuration.

Il existe plusieurs modèle pour le calculer, et celui que l'on utilisera est le modèle d'Ising.

\[U(x_s) = -\beta x_s \sum_{t\in V_s}{x_t} -B\sum_{s\in S}{x_s}\]

Littéralement, le potentiel de s quand $X=x_s$ est la somme de la valeur des états de ses voisins multiplié par un facteur $-\beta$, plus la somme des valeurs de tous les sites de l'image multiplié par un facteur $-B$.

On remarquera par la suite que le plus important ce sont les signes des facteurs, et non leur valeur absolue. En effet, un $\beta < 0$ donnera $U(x_s)$ positif pour le cas où $x_s$ est globalement opposé à $V_s$, et vice versa pour $\beta > 0$.  
Le terme $-B\sum_{s\in S}{x_s}$ quant à lui n'a pas parru nécessaire pour le cas particulier de la restauration d'image, au vu de nos propre test et de la littérature sur le sujet. C'est pourquoi dans la majorité des algorithmes qui suivront, il est mis à zero.

## La mesure de Gibbs 

Maintenant, comment utiliser ce calcul de potentiel local pour calculer les probabilités qui nous interessent ? Considérons une image bruitée; la première idée qu'il vient pour retrouver la bonne image est d'essayer une par une toutes les configurations de $\Omega$, mais ce n'est pas envisageable devant son cardinal. Rien que pour une image en noir et blanc on part déjà sur des puissances de deux, une petite image de sept cent vingt pixels aura $2^720$ configurations différentes...

Pour autant, si on voulait essayer, il existe un  outil, la mesure de Gibbs, qui permet justement de calculer la probabilité $P(X=x)$.

\[P(X=x)=\frac{1}{Z}e^{-U(x)}\].  

Cependant $Z=\sum_{x\in \Omega}e^{-U(x)}$ représente une somme beaucoup trop grande pour être calculer en pratique, justement à cause de la taille de $\Omega$.

## L'hypothèse markovienne

Pour pallier au problème, une autre approche aussi intuitive pour restaurer cette image consiste à restaurer chaque pixel de l'image un par un, plutôt que considérer l'image dans son ensemble directement.  

A priori pour "deviner" quelle est la bonne valeur pour un pixel s, le mieux à faire est de regarder tous le reste de l'image $x^s$, et à partir de $x^s$ essayer d'exprimer $X_s$ pour trouver quelle valeur $x_s$ est la plus probable sachant $x^s$. Cependant, on fait l'hypothèse que connaître $V_s$ le voisinage proche de s est équivalent à connaître $x^s$, soit $P(X_s=x_s| X^s) = P(X_s=x_s|V_s)$. C'est l'hypothèse de Markov, et elle est assez naturelle quand on observe une image; un pixel blanc isolé avec autour de lui seulement des pixels rouges est une situation assez rare, les différentes parties de couleur uniforme d'une images étant souvent grande de plusieurs pixels, d'autant plus pour une image en noir et blanc dépourvue de dégradé. Faire l'hypothèse de Markov ne semble donc pas à priori ridicul. Et c'est grâce à cette hypothèse que l'on va pouvoir utiliser le modèle d'Ising pour le calcul de potentiel local.

La définition du voisinage de s peut varier, par son étendu et sa forme; le voisinage que nous utiliserons presque toujours est simplement l'ensemble des quatre plus proches voisins de s sur la verticale et l'horizontale. On essaira par la suite de modifier ce voisinage.



OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO
OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO
OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO

## La mesure de Gibbs locale


On sait la chose suivante:  
\[P(X_s=x_s)=\frac{1}{Z}e^{-U(x_s)}\]
\[P(X=x)=\frac{1}{Z}e^{-U(x)}\]  
Avec \[Z=\sum_{x\in \Omega}e^{-U(x)}\] la fonction de partition.  


OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO
OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO
OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO


## Adapation à la restauration d'image

Pour la restaurer une image, on comprend qu'il manque quelque chose au modèle d'Ising. Tel qu'il est, l'image bruitée initiale n'entre pas en ligne de compte pour le calcul du pententiel locale. Et étant donnée que c'est la configuration de plus basse énergie qui est la plus probable, avec ce modèle toute image bruitée devrait logiquement être restaurée en une l'image blanche ou un damier de pixel, qui sont bien les configurations de plus basse énergie selon le signe de $\beta$. Il faut donc ajouter un terme au modèle d'Ising pour que l'image bruitée initiale entre en ligne de compte. On pose: $U(x_s) = -\beta\  x_s\sum_{t\in V_s}{x_t}-B\ \sum_{s\in S}{x_s}-\alpha\ x_s^0$ avec $x_s^0$ la valeur du site s de l'image bruitée initiale, et $\alpha$ le facteur qui déterminera le poid que l'on accord à la configuration initiale.

# Des algorithmes pour la restauration d'image: Gibbs et Metropolis

Pour restaurer des images à l'aide des outils que l'on a vu, on peut utiliser les algorithmes de Metropolis ou de Gibbs. On présente les deux:  

### L'algorithme de métropolis

**étape 1** On choisit un site s de l'image. La façon de choisir est libre du moment que l'on est assuré de parcourir tous les sites de l'image.  
**étape 2** On tire au hasard une nouvelle valeur $\lambda$ dans $E$ privé de $x_s^0$   
**étape 3** On calcule les potentiels $U(x_s)$ et $U(\lambda)$  
**étape 4** On calcule le rapport $P(X_s=x_s)/P(X_s=\lambda)=exp(U(x_s)-U(\lambda))$  
**étape 5** On tire un nombre entre zero et un pour simuler la loi $exp(U(x_s)-U(\lambda))$. S'il est inférieur au rapport de Metropolis, on refuse le changement; s'il est supérieur ou égale on l'accept.  

### L'algorithme de Gibbs
**étape 1** Tirage d'un site comme pour Metropolis  
**étape 2** Calcul des potentiel pour toutes les valeurs de E  
**étape 3** Calcul de la probabilité conditionnelle locale  $P(X_s=x_s|V_s)=\frac{-exp(U(x_s|V_s))}{\sum_{\lambda \in E}exp(-U(\lambda|V_s))}$
**étape 4** Simulation de la loi ainsi faite, par tirage aléatoire, et mise à jour du site


## Codage en R
### Boite à outils

Avant de commencer à coder ces algorithmes, on a décider de créer quelques fonctions utiles pour faciliter la manipulation du code, et son amélioration.

- **bruiteur()** prend une image en argument et la retourne bruitée de la manière souhaitée. Pour l'instant on n'a étudié qu'un bruit consistant en une inversion de valeur des pixels avec la probabilité d'inversion p donnée en argument (souvent $p=0.25$). À l'avenir on pourra tester les performances de nos algorithmes pour des bruits différents, il suffira d'ajouter quelques lignes de code à cette fonction.  
- **imageGenerator()** regroupe les différentes images que l'on bruitera avec bruiteur() pour ensuite essayer de les restaurer. Logiquement un logiciel de restauration ne fait pas l'offre et la demande dans ses images, mais c'est beaucoup plus simple pour nous de fabriquer et bruiter les images que l'on veut restaurer, pour travailler les algorithmes. Comme image on a pour l'instant le rectangle, le losange, et une image constituée d'une alternance de bandes noire et blanche horizontales. Là encore de nouvelles formes peuvent être ajoutées plus tard à la fonction pour pouvoir les tester dans les différents algorithmes.  
- **correspondance()** permet de calculer de pourcentage de correspondance entre deux image données en arguments, donc dans notre cas l'image bruitée et l'image restaurée. Cela permet d'évaluler numériquement l'efficacité des algorithmes et de faire des comparaisons. 
  

```{r boiteOutils}
bruiteur=function(image, br, p){
  #fonction qui revoit l'image donnée en argument par la même image mais bruitée par la méthode demandée "br"
  imgBr <- image
  N <- dim(image)[1]
  bruit <- 0
  p <- 0.15
  #----binomiale----
  if(br== "rbinom"){bruit <- matrix(2*rbinom(N^2,1,1-p)-1,nrow=N,ncol=N)}
  
  #----poisson----      #futurs bruitages différents possibles
  #----normale----
  
  imgBr <- image*bruit
  return(imgBr)
}#func

#================================================================================================================

imageGenerator=function(forme, N){
  #fonction permettant de générer une matrice-image de forme choisie, et de taille N*N
  
  img <- matrix(-1, nrow= N, ncol= N)
  
  #----rectangle----
  if(forme== "rectangle"){
    img[(N/4):(N*3/4),(N/4):(N*3/4)] <- 1}
  
  #----losange----
  if(forme== "losange"){
    for (i in 1:N){
      for (j in 1:N){
        img[i,j]=-1+2*(abs(i-j)<=N/4)*(abs(i+j-N)<=N/4)  
      }}#for#for
  }#if
  
  #----bandes verticales----
  if(forme=="bande"){
    for (j in 1:(N/2)){ img[,2*j]=rep(1,N) }
  }#if
  
  return(img)
}#func

#================================================================================================================

correspondance=function(img0, img1, N){
  #fonction qui renvoit le pourcentage de correspondance entre deux images de mêmes tailles.
	
	nok <- 0 #nombre de pixels divergents
	
	for (i in (1:N)){
		for (j in (1:N)){
			if(img0[i,j] != img1[i,j]){nok <- nok+1}
		}#for
	}#for
	correspondance <- ((N^2)-nok)/(N^2)*100
	return(correspondance)
}#func
```


### L'algorithme de Gibbs

On propose un code en R pour l'algorithme de Gibbs. Des racourcis ont étés possibles du fait que s ne puisse prendre que deux états en tout. Si on voulait aujour passre à des images en nuance de gris ou même en couleur, il faudrait faire des modifications.

```{r A_1_gibbsIsing}
GibbsIsing = function(forme, N, p, B, beta, alpha, n){
  # fonction qui réalise l'échantilloneur de Gibbs, sur le modèle d'Ising, avec une image img1 bruitée à partir de img0, afin de restaurer cette image.
  
  #----création de l'image parfaite img0----
  img0 = imageGenerator(forme, N)
  #----création de l'image bruitée, avec ajout d'une bordure.
	img1 = matrix(0, nrow=N+2, ncol=N+2)
	img1[2:(N+1),2:(N+1)] = bruiteur(img0, "rbinom", p) 
	img2 = img1 #image tampon
  img3 = img1 #mémoire du bruit initiale
  
  for(k in 1:n){ #n parcours de pixels
    #----choix d'un site au hasard---
    i <- 1+ceiling(N*runif(1)) # indice entre 2 et N+1 pour éviter le contour
    j <- 1+ceiling(N*runif(1))
    
    #----changement de valeur au site choisi sur img2 (1 ou -1) pour représenter E en entier avec img1 et img2 (cas d'une image en noir et blanc)----
    img2[i,j] = -img1[i,j]
    
    #----voisinage----
    v = img1[i+1,j] + img1[i-1,j] + img1[i,j+1] + img1[i,j-1]
    
    #----potentiels (modele d'ising)----
    U1 = -B*img1[i,j]-img1[i,j]*(beta*v + alpha*img3[i,j])
    U2 = -B*img2[i,j]-img2[i,j]*(beta*v + alpha*img3[i,j])
    
    #----calcule de la proba conditionnelle locale----
    P <- exp(-U2)/(exp(-U1)+exp(-U2))
    
    if(runif(1)<= P){img1[i,j]= img2[i,j]}#on change la valeur du pixel
    else{img2[i,j] <- img1[i,j]} #on garde la valeur du pixel
  }#for
  
  #----affichage----
  par(mfrow=c(1,3))
  
  img3 <- img3[2:(N+1),2:(N+1)] #on retire les contours
	img1 <- img1[2:(N+1),2:(N+1)]
  
	image(1:N,1:N,img0)#image initiale
	image(1:N+2,1:N+2,img3)#image bruitée
	image(1:N+2,1:N+2,img1)#image restaurée
}
```


### L'algorithme de Metropolis

En R voici une manière de coder cet algorithme :

```{r A_2_metropolisIsing_BASIQUE}
metropolisIsing=function(forme, N, p, B, beta, alpha, n){
	#fonction qui réalise l'algorithme de Metropolis sur une image bruitée img1 (à partir de img0), pour restaurer cette image.
	
	#----création de l'image parfaite img0----
	img0 = imageGenerator(forme, N)
	
	#----création d'une image auxiliaire img1, avec bord plus long et bruitage----
	img1 = matrix(0, nrow=N+2, ncol=N+2)
	img1[2:(N+1),2:(N+1)] = bruiteur(img0, "rbinom", p)
	img2 = img1 #image tampon
	img3 = img1 #mémoire du bruit initiale

	for(k in 1:n){ #n visites de pixels
	
		#----choix d'un pixel au hasard----
		i <- 1+ceiling(N*runif(1)) # indice entre 2 et N+1
		j <- 1+ceiling(N*runif(1))
		
		#----tirage nouvelle valeure candidate----
		img2[i,j] = -img1[i,j]
	
		#----voisinage----
		v = img1[i+1,j] + img1[i-1,j] + img1[i,j+1] + img1[i,j-1]
	
		#----potentiels----
		U1 = -B*img1[i,j]-img1[i,j]*(beta*v + alpha*img3[i,j])#potentiel actuel
		U2 = -B*img2[i,j]-img2[i,j]*(beta*v + alpha*img3[i,j])#potentiel candidat
	
		#----proba conditionnelle locale----
		dU = U2-U1
		p <- exp(-dU)
		
		if(runif(1)<=p){img1[i,j]= -img1[i,j]}#on change la valeur du pixel
		else{img2[i,j] <- img1[i,j]} #on garde la valeur du pixel
	}#for
	
	#----affichage----
	img3 <- img3[2:(N+1),2:(N+1)] #on retire le contour
	img1 <- img1[2:(N+1),2:(N+1)]
	
	par(mfrow=c(1,3))
	image(1:N,1:N,img0)#image initiale
	image(1:N+2,1:N+2,img3)#image bruitée
	image(1:N+2,1:N+2,img1)#image restaurée
	return(c("pourcentage de restauration", correspondance(img0,img1,N)))
  
}#func
```


## Test du code et observation et résultats

> **Le paramètre alpha** détermine l'importance donnée à l'image bruitée initiale dans la probabilité conditionnelle $P(X_s=x_s|V_s)$.  
- Si alpha est trop grand devant $\beta$, les valeurs les plus probables seront toujours celles de l'image bruitée, et donc l'algorithme ne fera rien. Un exemple avec $\alpha = 5$ et $\beta = 1$, on voit en effet que l'image restaurée (à droite) n'est presque pas différente de celle bruitée:

```{r alpha_grand, echo=FALSE}
metropolisIsing("rectangle", 64, 0.25, 0, 0.66, 5, 10^5)
```


> Si $\alpha$ est trop petit voir nul, la configuration initiale va être oubliée itération après itération (on retombe sur le modèle d'Ising initial), et on va tendre vers l'image blanche, peu importe l'image de départ. Exemple avec $\alpha=0$, pour deux images différentes: on voit bien que les formes commencent à être détruites.


```{r alpha_nul, echo=FALSE}
metropolisIsing("rectangle", 64, 0.25, 0, 0.66, 0, 5*10^5)
metropolisIsing("losange", 64, 0.25, 0, 0.66, 0, 5*10^5)
```


> **Le paramètre $\beta$** quant à lui détermine quel motifs seront les plus probables, entre des pixels de mêmes valeurs ($\beta > 0$) ou bien une alternance de pixel banc et noir ($\beta < 0$). Illustration:

```{r, echo=FALSE}
metropolisIsing("rectangle", 64, 0.25, 0, -0.66, 0.33, 10^5)
```


```{r, echo=FALSE}
metropolisIsing("rectangle", 64, 0.25, 0, 0.66, 0.33, 10^5)
```


> **Le calcul du voisinage** se fait assez facilement en R, on regarde la valeur des quatre pixels à gauche à droit en haut et en bas du pixel. Plus tard on utilise la fonction Vstar(), qui permet en plus d'étendre ce voisinage.

> **Le parcours des sites_** peut se faire soit aléatoirement, soit systématiquement (ligne par ligne par exemple).


## Le recuit simulé

Il existe un autre algorithme sur la base de l'algorithme de métropolis, plus performant, et que l'on retrouve imanquablement dans la littérature sur le sujet, c'est l'algorithme de recuit simulé. Par rapport à Metropolis, on introduit une "température", c'est à dire un paramètre T qui va intervenir dans le calcul de la probabilité comme $P_T(X=x)=\frac{exp(\frac{-U(x)}{T})}{\sum_{\lambda \in S}exp(\frac{-U(\lambda)}{T})}$. Le rapport de métropolis devient alors $exp(\frac{U(x_s)-U(\lambda)}{T})$. Après chaque itération, on fait tendre T un peu plus vers 0. Le principe est que, en partant d'un T "grand" et en le faisant tendre "lentement" vers 0, on doit nécessairement tendre vers le minima global d'énergie.  
Reste à déterminer quellle valeur de T choisir au départ comme grande, à quelle vitesse le faire tendre vers 0... Pour l'instant on fait ces choix arbitrairement et en s'inspirant de la littérature sur le sujet. Il reste aussi à démontrer dans ce rapport comment modifier les paramètres à chaque itération permet de converger presque surement vers le minimum global d'énergie.


```{r recuitMetro}
recuitSimule=function(forme, N, p, B, beta, alpha, n){
	#fonction qui réalise l'algorithme de recuit simulé, pour restaurer img1
	
	#----création de l'image parfaite img0----
	img0 = imageGenerator(forme, N)
	
	#----création d'une image auxiliaire img1, avec bordure et bruit----
	img1 = matrix(0, nrow=N+2, ncol=N+2)
	img1[2:(N+1),2:(N+1)] = bruiteur(img0, "rbinom", p)
	img2 = img1 #image tampon
	img3 = img1 #mémoire du bruit initiale

	for(k in 1:n){ #n visites de pixels
	  
	  T <- 1/log(n) #T tend lentement vers 0
	  
		#----choix d'un pixel au hasard----
		i <- 1+ceiling(N*runif(1)) # indice entre 2 et N+1
		j <- 1+ceiling(N*runif(1))
		
		#----tirage nouvelle valeure candidate----
		img2[i,j] = -img1[i,j]
	
		#----voisinage----
		v = img1[i+1,j] + img1[i-1,j] + img1[i,j+1] + img1[i,j-1]
	
		#----potentiels----
		U1 = -B*img1[i,j]-img1[i,j]*(beta*v + alpha*img3[i,j])#potentiel actuel
		U2 = -B*img2[i,j]-img2[i,j]*(beta*v + alpha*img3[i,j])#potentiel candidat
	
		#----probabilité conditionnelle locale, "recuite" à chaque itération----
		dU = U2-U1
		p <- exp(-dU/T)
		
		if(runif(1)<=p){img1[i,j]= -img1[i,j]}#changement
		else{img2[i,j] <- img1[i,j]} #inchangé
	}#for
	
	#----affichage----
	img3 <- img3[2:(N+1),2:(N+1)] #retire le contour
	img1 <- img1[2:(N+1),2:(N+1)]
	
	par(mfrow=c(1,3))
	image(1:N,1:N,img0)#image initiale
	image(1:N+2,1:N+2,img3)#image  bruitée
	image(1:N+2,1:N+2,img1)#image restaurée
	return(c("pourcentage de restauration", correspondance(img0,img1,N)))
  
}#func
```


> **Comparaison de performance** entre l'algorithme de recuit et celui de Metropolis. On ajoute la fonction de correspondance au deux pour comparer numériquement.

```{r include=FALSE}

```


```{r, echo=FALSE}
recuitSimule("rectangle", 64, 0.25, 0, 0.66, 0.33, 5*10^4)
metropolisIsing("rectangle", 64, 0.25, 0, 0.66, 0.33, 5*10^4)
```


On peut comparer les performances entre le recuit simulé et l'algorithme de Metropolis en comparant le pourcentage de restauration des deux algorithmes, à paramètres et image bruitée identique.

```{r}
#peut être afficher le code, mais on pourrait juste donner le résultat, et les images.

```


# Estimation du paramètre $\beta$

L'algorithme de recuit précédent marche plutôt bien pour des images pleines (rectangle, losange), mais si on éssaie de restaurer une image en plusieurs parties, une succession de bandes par exemple, ou un damier, l'algorithme ne fonctionne plus du tout. 

```{r}
#metropolisIsing("ligne", 64, 1, 0, 1, 10, 10^4, 0.15)

```


## Distinction des énergies verticales et horizontales

Une idée que l'on peut avoir pour palier au problème est de séparer les calcules de potentiels entre la verticale et l'horizontale, en appliquant à chaque terme un facteur beta dédié à une orientation, $\beta_h$ pour l'horizontale et $\beta_v$ pour la verticale. On a ainsi: $U(x_s)= -x_s[\beta_h(x_d+x_g)+\beta_v(x_h+x_b)+\alpha x_s^0]$ avec $x_d,x_g,x_h,x_b$ les valeurs des pixels voisins du site s respectivement à droite, gauche, haut, bas. On modifie l'algorithme de recuit pour essayer:

```{r}

```


On peut ainsi avoir des signes différents pour $\beta_h$ et $\beta_v$, et donc privilégier les lignes pour une direction et les alternances blanc/noir dans l'autre direction. Pour l'exemple précédent avec des lignes horizontales, on va choisir $\beta_h > 0$ pour privilégier les lignes sur l'horizontale et $\beta_v < 0$ pour privilégier l'alternance des pixels sur la verticale. CE N'EST PAS CA!!! CALCUL AUTOMATIQUE

```{r}
#algo qui va bien
```


## Voisinage de taille variable

Une autre manière de résoudre ce problème de restoration de bandes pourrait aussi se trouver dans l'étendue du voisinage. 

```{r}
#algo vbranche vstart
```

```{r}
#algo de recuit avec calcul de voisinage étendu et donc parametre L
```


REMARQUE A FAIRE QUAND MEME: en augmentant l'amplitude du voisinage comme on le fait là, on constate que la restauration des images est plus propre (confère au graphique que l'on avait fait, essayer de les remettre)

# Amélioration de la rapidité des algorithmes

Depuis le début, on fixe le nombre d'itérations de l'algorithme (souvent à $10^4$ ou $10^5$). Cependant, on peut supposer que parfois il ne soit pas nécessaire de faire autant d'itération pour arriver à un résultat correct. De plus, le bruitage est réalisé aléatoirement, et donc d'une exécution de d'algorithme à une autre, le nombre d'itérations nécessaires pour restaurer l'image ne sera pas forcément le même.  

Une manière de rendre le nombre d'itérations variable serait de le conditionner au nombre de parcours de site successifs sans changement de valeurs. On pourra ainsi déclarer arbitrairement que, dès que l'algorithme réalise dix itérations successives sans changement de valeur, il s'arrête. Le mieux serait de déterminer a priori, étant donnée l'image bruitée, le nombre minimal d'itérations successives sans modification à réaliser pour la restaurer à un certain pourcentage.  

C'est ce que l'on fait dans l'algorithme de recuit simulé suivant:

```{r nconsécutif}
#algo qui va bien
```

Pour aller encore plus vite, au lieu d'attendre dix itérations successives sans aucune modification, on pourrait arrêter l'algorithme dès que, au cours des dix dernières itérations, il y a eu plus 1 modification. On peut jouer sur ces deux paramètres (taille de la "fenêtre coulissante", ici 10, et nombre maximum de changements, 0 dans votre exemple, et ici 1).

```{r nminimum}
#algo modifié
```

  
# Evolution de la restauration en fonction d'un nombre d'itérations

Avec des algorithmes dont le nombre d'itération varie, on peut se demander quelle est la probabilité d'avoir une image restaurée à un H%, après n itérations consécutives sans changements.


Une première majoration très grossière peut être de considérer l'ensemble des images de plus hautes énergie, et de déterminer combien d'itération il faut au minimum pour les ramener à l'image blanche. Ce nombre sera forcément supérieur ou égale au nombre d'itérations nécessaires pour n'importe quel image donnée de même taille. 

## Probabilité d'avoir la configuration d'énergie minimale 

### Estimation du nombre de parcours minimum nécessaires à la restauration d'une image pour toute image donnée
Une première majoration très grossière peut se faire en passant l'image de départ à restaurer comme variable, pour laquelle nous n'avons à priori aucune informations. Peut importe l'image à restaurer, combien de parcours de site l'algorithme doit-il réaliser ?  

Pour un voisinage classique avec 4 voisins prenna valeur dans $\{-1,1\}$, on a $2^4=16$ configurations de voisinages possibles.  

L'avantage de notre approche, c'est qu'en l'absence d'information sur l'image à restaurer, on peut raisonnable considérer ces 16 configurations de voisinage comme équiprobables.

D'un point de vu énergétique, il n'y a que 5 cas possibles. $V_s\in\{-4,\ -2,\ 0,\ 2,\ 4\}$.


### Probabilité de succès pour un pixel
### Probabilité de succès pour une configuration complète

## Probabilité d'avoir restauré l'image à H%
