---
title: "Restauration d'image grâce aux chaînes de markov"
author: "Clément Thion"
date: "06/2020"
output:
  html_document:
    df_print: paged
  pdf_document: default
---

```{r, include=FALSE}
library(stats)
library(survival)
library(ggplot2)
```

# Introduction

L'objectif final de ce stage est de restaurer algorithmiquement des images binaires (assez simples) en noir et blanc ayant subi un bruitage. Pour cela on utilise les chaînes de Markov et des modèles énergétiques sur les images, principalement le modèle d'Ising et la mesure de Gibbs, afin de pouvoir estimer de manière probabiliste les meilleures configurations pour la restauration. Les algorithmes ainsi constitués sont ensuite codés en R pour être testés.    

Dans dans son état actuel, ce rapport abborde plusieurs question en lien avec le sujet mais est très loin d'être complet. Une grande part des observations sont encore d'ordre empirique et nécessiteraient d'être approfondies sur le plan théorique. Pour autant on dispose déjà de plusieurs algorithmes fonctionnels permettant une restauration satisfaisante d'images simples.

## Modélisation d'une image

Afin de pouvoir manipuler des images, on utilise les notations et appellations suivantes:  
- x : une configuration d'une grille de pixels donnée (une image donc), parmis l'ensemble des configurations possibles $\Omega$. On note X la variable aléatoire décrivant x.   
- s : un pixel de l'image (on appelle aussi les pixels des "sites"), avec $x_s$ sa valeur. $x_s\in E$ l'ensemble des valeurs possibles possibles d'un pixel. E varie selon le type d'image (couleur, noir et blanc). Pour faciliter le travail, on ne manipule ici que des images en noir et blanc, donc $E=\{-1,1\}$.On note $X_s$ la variable aléatoire décrivant les différents états de $x_s$.  
- $X^s$ :la variable aléatoire décrivant la configuration de l'image privée du pixel $s$. $x^s$ est donc une fonfiguration x donnée, privée de s.  
- $V_s$ : le voisinage de s, que l'on définira plus tard.
- $U$ : le potentiel d'un pixel ou d'une image dans une configuration donnée, appelé aussi énergie.

## Le modèle d'Ising

Afin de calculer des probabilités sur les configurations possibles, on introduit la notion de potentiel U. Le potentiel d'une configuration de pixels, que ce soit l'image en entier ou localement un pixel de l'image et son voisinage, c'est une valeur numérique qui dépend des valeurs des pixels de la configuration.

Il existe plusieurs modèle pour le calculer, et celui que l'on utilisera est le modèle d'Ising.

\[U(x_s) = -\beta x_s \sum_{t\in V_s}{x_t} -B\sum_{s\in S}{x_s}\]

Littéralement, le potentiel de s quand $X=x_s$ est la somme de la valeur des états de ses voisins multiplié par un facteur $-\beta$, plus la somme des valeurs de tous les sites de l'image multiplié par un facteur $-B$.

On remarquera par la suite que le plus important ce sont les signes des facteurs, et non leur valeur absolue. En effet, un $\beta < 0$ donnera $U(x_s)$ positif pour le cas où $x_s$ est globalement opposé à $V_s$, et vice versa pour $\beta > 0$.  
Le terme $-B\sum_{s\in S}{x_s}$ quant à lui n'a pas parru nécessaire pour le cas particulier de la restauration d'image, au vu de nos propre test et de la littérature sur le sujet. C'est pourquoi dans la majorité des algorithmes qui suivront, il est mis à zero.

## La mesure de Gibbs 

Maintenant, comment utiliser ce calcul de potentiel local pour calculer les probabilités qui nous interessent ? Considérons une image bruitée; la première idée qu'il vient pour retrouver la bonne image est d'essayer une par une toutes les configurations de $\Omega$, mais ce n'est pas envisageable devant son cardinal. Rien que pour une image en noir et blanc on part déjà sur des puissances de deux, une petite image de sept cent vingt pixels aura $2^720$ configurations différentes...

Pour autant, si on voulait essayer, il existe un  outil, la mesure de Gibbs, qui permet justement de calculer la probabilité $P(X=x)$.

\[P(X=x)=\frac{1}{Z}e^{-U(x)}\].  

Cependant $Z=\sum_{x\in \Omega}e^{-U(x)}$ représente une somme beaucoup trop grande pour être calculer en pratique, justement à cause de la taille de $\Omega$.

## L'hypothèse markovienne

Pour pallier au problème, une autre approche aussi intuitive pour restaurer cette image consiste à restaurer chaque pixel de l'image un par un, plutôt que considérer l'image dans son ensemble directement.  

A priori pour "deviner" quelle est la bonne valeur pour un pixel s, le mieux à faire est de regarder tous le reste de l'image $x^s$, et à partir de $x^s$ essayer d'exprimer $X_s$ pour trouver quelle valeur $x_s$ est la plus probable sachant $x^s$. Cependant, on fait l'hypothèse que connaître $V_s$ le voisinage proche de s est équivalent à connaître $x^s$, soit $P(X_s=x_s| X^s) = P(X_s=x_s|V_s)$. C'est l'hypothèse de Markov, et elle est assez naturelle quand on observe une image; un pixel blanc isolé avec autour de lui seulement des pixels rouges est une situation assez rare, les différentes parties de couleur uniforme d'une images étant souvent grande de plusieurs pixels, d'autant plus pour une image en noir et blanc dépourvue de dégradé. Faire l'hypothèse de Markov ne semble donc pas à priori ridicul. Et c'est grâce à cette hypothèse que l'on va pouvoir utiliser le modèle d'Ising pour le calcul de potentiel local.

La définition du voisinage de s peut varier, par son étendu et sa forme; le voisinage que nous utiliserons presque toujours est simplement l'ensemble des quatre plus proches voisins de s sur la verticale et l'horizontale. On essaira par la suite de modifier ce voisinage.



OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO
OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO
OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO

## La mesure de Gibbs locale


On sait la chose suivante:  
\[P(X_s=x_s)=\frac{1}{Z}e^{-U(x_s)}\]
\[P(X=x)=\frac{1}{Z}e^{-U(x)}\]  
Avec \[Z=\sum_{x\in \Omega}e^{-U(x)}\] la fonction de partition.  


OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO
OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO
OOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOOO


## Adapation à la restauration d'image

Pour la restaurer une image, on comprend qu'il manque quelque chose au modèle d'Ising. Tel qu'il est, l'image bruitée initiale n'entre pas en ligne de compte pour le calcul du pententiel locale. Et étant donnée que c'est la configuration de plus basse énergie qui est la plus probable, avec ce modèle toute image bruitée devrait logiquement être restaurée en une l'image blanche ou un damier de pixel, qui sont bien les configurations de plus basse énergie selon le signe de $\beta$. Il faut donc ajouter un terme au modèle d'Ising pour que l'image bruitée initiale entre en ligne de compte. On pose: $U(x_s) = -\beta\  x_s\sum_{t\in V_s}{x_t}-B\ \sum_{s\in S}{x_s}-\alpha\ x_s^0$ avec $x_s^0$ la valeur du site s de l'image bruitée initiale, et $\alpha$ le facteur qui déterminera le poid que l'on accord à la configuration initiale.

# Des algorithmes pour la restauration d'image: Gibbs et Metropolis

Pour restaurer des images à l'aide des outils que l'on a vu, on peut utiliser les algorithmes de Metropolis ou de Gibbs. On présente les deux:  

### L'algorithme de métropolis

**étape 1** On choisit un site s de l'image. La façon de choisir est libre du moment que l'on est assuré de parcourir tous les sites de l'image.  
**étape 2** On tire au hasard une nouvelle valeur $\lambda$ dans $E$ privé de $x_s^0$   
**étape 3** On calcule les potentiels $U(x_s)$ et $U(\lambda)$  
**étape 4** On calcule le rapport $P(X_s=x_s)/P(X_s=\lambda)=exp(U(x_s)-U(\lambda))$  
**étape 5** On tire un nombre entre zero et un pour simuler la loi $exp(U(x_s)-U(\lambda))$. S'il est inférieur au rapport de Metropolis, on refuse le changement; s'il est supérieur ou égale on l'accept.  

### L'algorithme de Gibbs
**étape 1** Tirage d'un site comme pour Metropolis  
**étape 2** Calcul des potentiel pour toutes les valeurs de E  
**étape 3** Calcul de la probabilité conditionnelle locale  $P(X_s=x_s|V_s)=\frac{-exp(U(x_s|V_s))}{\sum_{\lambda \in E}exp(-U(\lambda|V_s))}$
**étape 4** Simulation de la loi ainsi faite, par tirage aléatoire, et mise à jour du site


## Codage en R
### Boite à outils

Avant de commencer à coder ces algorithmes, on a décider de créer quelques fonctions utiles pour faciliter la manipulation du code, et son amélioration.

- **bruiteur()** prend une image en argument et la retourne bruitée de la manière souhaitée. Pour l'instant on n'a étudié qu'un bruit consistant en une inversion de valeur des pixels avec la probabilité d'inversion p donnée en argument (souvent $p=0.25$). À l'avenir on pourra tester les performances de nos algorithmes pour des bruits différents, il suffira d'ajouter quelques lignes de code à cette fonction.  
- **imageGenerator()** regroupe les différentes images que l'on bruitera avec bruiteur() pour ensuite essayer de les restaurer. Logiquement un logiciel de restauration ne fait pas l'offre et la demande dans ses images, mais c'est beaucoup plus simple pour nous de fabriquer et bruiter les images que l'on veut restaurer, pour travailler les algorithmes. Comme image on a pour l'instant le rectangle, le losange, et une image constituée d'une alternance de bandes noire et blanche horizontales. Là encore de nouvelles formes peuvent être ajoutées plus tard à la fonction pour pouvoir les tester dans les différents algorithmes.  
- **correspondance()** permet de calculer de pourcentage de correspondance entre deux image données en arguments, donc dans notre cas l'image bruitée et l'image restaurée. Cela permet d'évaluler numériquement l'efficacité des algorithmes et de faire des comparaisons. 
  

```{r boiteOutils}
bruiteur=function(image, br, p){
  #fonction qui revoit l'image donnée en argument par la même image mais bruitée par la méthode demandée "br"
  imgBr <- image
  N <- dim(image)[1]
  bruit <- 0
  p <- 0.15
  #----binomiale----
  if(br== "rbinom"){bruit <- matrix(2*rbinom(N^2,1,1-p)-1,nrow=N,ncol=N)}
  
  #----poisson----      #futurs bruitages différents possibles
  #----normale----
  
  imgBr <- image*bruit
  return(imgBr)
}#func

#================================================================================================================

imageGenerator=function(forme, N){
  #fonction permettant de générer une matrice-image de forme choisie, et de taille N*N
  
  img <- matrix(-1, nrow= N, ncol= N)
  
  #----rectangle----
  if(forme== "rectangle"){
    img[(N/4):(N*3/4),(N/4):(N*3/4)] <- 1}
  
  #----losange----
  if(forme== "losange"){
    for (i in 1:N){
      for (j in 1:N){
        img[i,j]=-1+2*(abs(i-j)<=N/4)*(abs(i+j-N)<=N/4)  
      }}#for#for
  }#if
  
  #----bandes verticales----
  if(forme=="bande"){
    for (j in 1:(N/2)){ img[,2*j]=rep(1,N) }
  }#if
  
  return(img)
}#func

#================================================================================================================

correspondance=function(img0, img1, N){
  #fonction qui renvoit le pourcentage de correspondance entre deux images de mêmes tailles.
	
	nok <- 0 #nombre de pixels divergents
	
	for (i in (1:N)){
		for (j in (1:N)){
			if(img0[i,j] != img1[i,j]){nok <- nok+1}
		}#for
	}#for
	correspondance <- ((N^2)-nok)/(N^2)*100
	return(correspondance)
}#func
```


### L'algorithme de Gibbs

On propose un code en R pour l'algorithme de Gibbs. Des racourcis ont étés possibles du fait que s ne puisse prendre que deux états en tout. Si on voulait aujour passre à des images en nuance de gris ou même en couleur, il faudrait faire des modifications.

```{r A_1_gibbsIsing}
GibbsIsing = function(forme, N, p, B, beta, alpha, n){
  # fonction qui réalise l'échantilloneur de Gibbs, sur le modèle d'Ising, avec une image img1 bruitée à partir de img0, afin de restaurer cette image.
  
  #----création de l'image parfaite img0----
  img0 = imageGenerator(forme, N)
  #----création de l'image bruitée, avec ajout d'une bordure.
	img1 = matrix(0, nrow=N+2, ncol=N+2)
	img1[2:(N+1),2:(N+1)] = bruiteur(img0, "rbinom", p) 
	img2 = img1 #image tampon
  img3 = img1 #mémoire du bruit initiale
  
  for(k in 1:n){ #n parcours de pixels
    #----choix d'un site au hasard---
    i <- 1+ceiling(N*runif(1)) # indice entre 2 et N+1 pour éviter le contour
    j <- 1+ceiling(N*runif(1))
    
    #----changement de valeur au site choisi sur img2 (1 ou -1) pour représenter E en entier avec img1 et img2 (cas d'une image en noir et blanc)----
    img2[i,j] = -img1[i,j]
    
    #----voisinage----
    v = img1[i+1,j] + img1[i-1,j] + img1[i,j+1] + img1[i,j-1]
    
    #----potentiels (modele d'ising)----
    U1 = -B*img1[i,j]-img1[i,j]*(beta*v + alpha*img3[i,j])
    U2 = -B*img2[i,j]-img2[i,j]*(beta*v + alpha*img3[i,j])
    
    #----calcule de la proba conditionnelle locale----
    P <- exp(-U2)/(exp(-U1)+exp(-U2))
    
    if(runif(1)<= P){img1[i,j]= img2[i,j]}#on change la valeur du pixel
    else{img2[i,j] <- img1[i,j]} #on garde la valeur du pixel
  }#for
  
  #----affichage----
  par(mfrow=c(1,3))
  
  img3 <- img3[2:(N+1),2:(N+1)] #on retire les contours
	img1 <- img1[2:(N+1),2:(N+1)]
  
	image(1:N,1:N,img0)#image initiale
	image(1:N+2,1:N+2,img3)#image bruitée
	image(1:N+2,1:N+2,img1)#image restaurée
}
```


### L'algorithme de Metropolis

En R voici une manière de coder cet algorithme :

```{r A_2_metropolisIsing_BASIQUE}
metropolisIsing=function(forme, N, p, B, beta, alpha, n){
	#fonction qui réalise l'algorithme de Metropolis sur une image bruitée img1 (à partir de img0), pour restaurer cette image.
	
	#----création de l'image parfaite img0----
	img0 = imageGenerator(forme, N)
	
	#----création d'une image auxiliaire img1, avec bord plus long et bruitage----
	img1 = matrix(0, nrow=N+2, ncol=N+2)
	img1[2:(N+1),2:(N+1)] = bruiteur(img0, "rbinom", p)
	img2 = img1 #image tampon
	img3 = img1 #mémoire du bruit initiale

	for(k in 1:n){ #n visites de pixels
	
		#----choix d'un pixel au hasard----
		i <- 1+ceiling(N*runif(1)) # indice entre 2 et N+1
		j <- 1+ceiling(N*runif(1))
		
		#----tirage nouvelle valeure candidate----
		img2[i,j] = -img1[i,j]
	
		#----voisinage----
		v = img1[i+1,j] + img1[i-1,j] + img1[i,j+1] + img1[i,j-1]
	
		#----potentiels----
		U1 = -B*img1[i,j]-img1[i,j]*(beta*v + alpha*img3[i,j])#potentiel actuel
		U2 = -B*img2[i,j]-img2[i,j]*(beta*v + alpha*img3[i,j])#potentiel candidat
	
		#----proba conditionnelle locale----
		dU = U2-U1
		p <- exp(-dU)
		
		if(runif(1)<=p){img1[i,j]= -img1[i,j]}#on change la valeur du pixel
		else{img2[i,j] <- img1[i,j]} #on garde la valeur du pixel
	}#for
	
	#----affichage----
	img3 <- img3[2:(N+1),2:(N+1)] #on retire le contour
	img1 <- img1[2:(N+1),2:(N+1)]
	
	par(mfrow=c(1,3))
	image(1:N,1:N,img0)#image initiale
	image(1:N+2,1:N+2,img3)#image bruitée
	image(1:N+2,1:N+2,img1)#image restaurée
	return(c("pourcentage de restauration par metropolisIsing", correspondance(img0,img1,N)))
  
}#func
```


## Test du code et observation et résultats

> **Le paramètre alpha** détermine l'importance donnée à l'image bruitée initiale dans la probabilité conditionnelle $P(X_s=x_s|V_s)$.  
- Si alpha est trop grand devant $\beta$, les valeurs les plus probables seront toujours celles de l'image bruitée, et donc l'algorithme ne fera rien. Un exemple avec $\alpha = 5$ et $\beta = 1$, on voit en effet que l'image restaurée (à droite) n'est presque pas différente de celle bruitée:

```{r alpha_grand, echo=FALSE}
metropolisIsing("rectangle", 64, 0.25, 0, 0.66, 5, 10^5)
```


> Si $\alpha$ est trop petit voir nul, la configuration initiale va être oubliée itération après itération (on retombe sur le modèle d'Ising initial), et on va tendre vers l'image blanche, peu importe l'image de départ. Exemple avec $\alpha=0$, pour deux images différentes: on voit bien que les formes commencent à être détruites.


```{r alpha_nul, echo=FALSE}
metropolisIsing("rectangle", 64, 0.25, 0, 0.66, 0, 5*10^5)
metropolisIsing("losange", 64, 0.25, 0, 0.66, 0, 5*10^5)
```


> **Le paramètre $\beta$** quant à lui détermine quel motifs seront les plus probables, entre des pixels de mêmes valeurs ($\beta > 0$) ou bien une alternance de pixel banc et noir ($\beta < 0$). Par exemple pour restaurer le rectangle, on constate bien que le $\beta$ positif est nettement préférable au $\beta$ négatif, du fait que le rectangle est une image d'un seul bloc. Illustration avec $\beta=+-0.66$

```{r, echo=FALSE}
metropolisIsing("rectangle", 64, 0.25, 0, -0.66, 0.33, 10^5)
```


```{r, echo=FALSE}
metropolisIsing("rectangle", 64, 0.25, 0, 0.66, 0.33, 10^5)
```


> **Le calcul du voisinage** se fait assez facilement en R, on regarde la valeur des quatre pixels à gauche à droit en haut et en bas du pixel. Plus tard on utilise la fonction Vstar(), qui permet en plus d'étendre ce voisinage.

> **Le parcours des sites_** peut se faire soit aléatoirement, soit systématiquement (ligne par ligne par exemple).


## Le recuit simulé

Il existe un autre algorithme sur la base de l'algorithme de métropolis, plus performant, et que l'on retrouve imanquablement dans la littérature sur le sujet, c'est l'algorithme de recuit simulé. Par rapport à Metropolis, on introduit une "température", c'est à dire un paramètre T qui va intervenir dans le calcul de la probabilité comme $P_T(X=x)=\frac{exp(\frac{-U(x)}{T})}{\sum_{\lambda \in S}exp(\frac{-U(\lambda)}{T})}$. Le rapport de métropolis devient alors $exp(\frac{U(x_s)-U(\lambda)}{T})$. Après chaque itération, on fait tendre T un peu plus vers 0. Le principe est que, en partant d'un T "grand" et en le faisant tendre "lentement" vers 0, on doit nécessairement tendre vers le minima global d'énergie.  
Reste à déterminer quellle valeur de T choisir au départ comme grande, à quelle vitesse le faire tendre vers 0... Pour l'instant on fait ces choix arbitrairement et en s'inspirant de la littérature sur le sujet. Il reste aussi à démontrer dans ce rapport comment modifier les paramètres à chaque itération permet de converger presque surement vers le minimum global d'énergie.


```{r recuitMetro}
recuitSimule=function(forme, N, p, B, beta, alpha, n){
	#fonction qui réalise l'algorithme de recuit simulé, pour restaurer img1
	
	#----création de l'image parfaite img0----
	img0 = imageGenerator(forme, N)
	
	#----création d'une image auxiliaire img1, avec bordure et bruit----
	img1 = matrix(0, nrow=N+2, ncol=N+2)
	img1[2:(N+1),2:(N+1)] = bruiteur(img0, "rbinom", p)
	img2 = img1 #image tampon
	img3 = img1 #mémoire du bruit initiale

	for(k in 1:n){ #n visites de pixels
	  
	  T <- 1/log(k+1) #T tend lentement vers 0
	  
		#----choix d'un pixel au hasard----
		i <- 1+ceiling(N*runif(1)) # indice entre 2 et N+1
		j <- 1+ceiling(N*runif(1))
		
		#----tirage nouvelle valeure candidate----
		img2[i,j] = -img1[i,j]
	
		#----voisinage----
		v = img1[i+1,j] + img1[i-1,j] + img1[i,j+1] + img1[i,j-1]
	
		#----potentiels----
		U1 = -B*img1[i,j]-img1[i,j]*(beta*v + alpha*img3[i,j])#potentiel actuel
		U2 = -B*img2[i,j]-img2[i,j]*(beta*v + alpha*img3[i,j])#potentiel candidat
	
		#----probabilité conditionnelle locale, "recuite" à chaque itération----
		dU = U2-U1
		p <- exp(-dU/T)
		
		if(runif(1)<=p){img1[i,j]= -img1[i,j]}#changement
		else{img2[i,j] <- img1[i,j]} #inchangé
	}#for
	
	#----affichage----
	img3 <- img3[2:(N+1),2:(N+1)] #retire le contour
	img1 <- img1[2:(N+1),2:(N+1)]
	
	par(mfrow=c(1,3))
	image(1:N,1:N,img0)#image initiale
	image(1:N+2,1:N+2,img3)#image  bruitée
	image(1:N+2,1:N+2,img1)#image restaurée
	return(c("pourcentage de restauration par recuitSimule", correspondance(img0,img1,N)))
  
}#func
```


> **Comparaison de performance** On constate que la différence de performance de restauration est quasiment nulle entre les deux algorithmes.


```{r, echo=FALSE}
recuitSimule("rectangle", 64, 0.25, 0, 0.66, 0.33, 5*10^4)
metropolisIsing("rectangle", 64, 0.25, 0, 0.66, 0.33, 5*10^4)
```


# Estimation du paramètre $\beta$

L'algorithme de recuit précédent marche plutôt bien pour des images pleines (rectangle, losange), mais si on éssaie de restaurer une image en plusieurs parties, une succession de bandes par exemple, ou un damier, l'algorithme ne fonctionne plus du tout, peu importe le signe de $\beta$ : 

```{r}
recuitSimule("bande", 64, 0.25, 0, 0.66, 0.33, 5*10^4)
```

```{r}
recuitSimule("bande", 64, 0.25, 0, -0.66, 0.33, 5*10^4)
```


## Distinction des énergies verticales et horizontales

Une idée que l'on peut avoir pour palier au problème est de séparer les calcules de potentiels entre la verticale et l'horizontale, en appliquant à chaque terme un facteur $\beta$ dédié à une orientation. On modifie l'algorithme de recuit pour essayer, en changeant le chose comme suit:     

- le calcule de voisinage est divisé en deux termes, les voisins sur l'horizontale Vh et ceux sur la verticale Vv.
- Le terme concernant le voisinage dans le calcul de U est maintenant cindé en deux, avec deux $\beta$ différents, $\beta_h$ pour l'horizontale et $\beta_v$ pour la verticale. On a ainsi: $U(x_s)= -x_s[\beta_h(x_d+x_g)+\beta_v(x_h+x_b)+\alpha x_s^0]$ avec $x_d,x_g,x_h,x_b$ les valeurs des pixels voisins du site s respectivement à droite, gauche, haut, bas.
- Les signes respectifs des deux $\beta$ sont calculés en faisant une analyse du signe globale de l'image sur l'orizontale et la verticale. Pour se faire on utilise la fonction ernergiehv(), qui réalise les somme des doubles produit des couple de pixels voisins, sur la verticale pour une somme et sur l'horizontale pour l'autre. Dans le cas des bandes horizontales par exemple, on voudrait avoir un $\beta_h>0$ et un $\beta_v<0$. En effet une ligne horizontale de l'image est constituée de pixel identiques, on veut donc que soit privilégié l'égalité de valeur entre $x_s$ et $x_t,\ t\in V_s$. Sur une ligne verticale, c'est l'inverse.


```{r, restoreStripe}
restorStripe=function(forme, N, p, B, beta, alpha, n){
  #fonction de recuit simulé modifiée pour restaurer une image en bandes horizontales noir et blanche alternées, grâce à une disjonction de cas entre l'horizontale et la verticale pour les calculs de potentiel.
  
  energiehv=function(img){
    #fonction qui renvoie, dans un tuple, les sommes des doubles produits sur les lignes, et sur les colonnes. Le résultats sert au calcul des betah et betav
    eligne=0
    ecolonne=0
    for (i in 1:N) {for (j in 1:(N-1)){eligne=eligne+img[i,j]*img[i,j+1]}}  #somme des doubles produits de ligne
    for (j in 1:N) {for (i in 1:(N-1)){ecolonne=ecolonne+img[i,j]*img[i+1,j]}}  #somme des doubles produits de colonne
    return(c(eligne,ecolonne))
  }#func
  
  
  #----img0, initiale----
  img0 = imageGenerator(forme, N)
  
  #----img1, avec bordure et bruit----
  img1 = matrix(0, nrow=N+2, ncol=N+2)
  img1[2:(N+1),2:(N+1)] = bruiteur(img0, "rbinom", p)
  img2 = img1 #tampon
  img3 = img1 #bruit initiale
  
  #----calcul des deux beta, horizontal et vertical----
  betah=2*energiehv(img1)[2]/(abs(energiehv(img1)[1])+abs(energiehv(img1)[2]))
  betav=2*energiehv(img1)[1]/(abs(energiehv(img1)[1])+abs(energiehv(img1)[2]))

	for(k in 1:n){ #n visites de pixels
	  
	  T <- 1/log(n)
	  
		#----choix d'un pixel au hasard----
		i <- 1+ceiling(N*runif(1))
		j <- 1+ceiling(N*runif(1))
		
		#----tirage nouvelle valeure candidate----
		img2[i,j] = -img1[i,j]
	
    #----calcule du voisinage séparément entre horizontale (Vh) et verticale (Vv)
    Vh <- img1[i-1,j]+img1[i+1,j]
    Vv <- img1[i,j-1]+img1[i,j+1]
	
		#----potentiels----
		U1 = -B*img1[i,j]-img1[i,j]*(betah*Vh + betav*Vv + alpha*img3[i,j])#potentiel actuel
		U2 = -B*img2[i,j]-img2[i,j]*(betah*Vh + betav*Vv + alpha*img3[i,j])#potentiel candidat
	
		#----test----
		dU = U2-U1
		p <- exp(-dU/T)
		
		if(runif(1)<=p){img1[i,j]= -img1[i,j]}#changé
		else{img2[i,j] <- img1[i,j]} #inchangé
	}#for
  
  
  #----affichage----
  img3 <- img3[2:(N+1),2:(N+1)] 
  img1 <- img1[2:(N+1),2:(N+1)]
  par(mfrow=c(1,3))
  image(1:N,1:N,img0)#image initiale
  image(1:N+2,1:N+2,img3)#image bruitée
  image(1:N+2,1:N+2,img1)#image restaurée
  
  return(c("pourcentage de restauration par restorStripe",correspondance(img0,img1,N),"betah",betah,"betav",betav))
  
}#func
```


```{r}
restorStripe("bande",64,0.25,0,0.66,0.33,5*10^4)
```


## Voisinage de taille variable

Une autre piste à creuser pour répondre au problème de restauration des bandes, ce serait de changer la définition du voisinage. L'idée est la suivante: la taille et la forme du voisinage change d'un pixel à l'autre. Seul les pixels sur les lignes verticales et horizontales où se trouve s peuvent faire partie de $V_s$, comme pour le voisinage habituel haut bas gauche droite. 

On définit le voisinage comme une étoile à quatres branches, deux sur l'horizontale (une à gauche de s, l'autre à droite), et deux sur la verticale (l'une en haut de s et l'autre en bas). On peut donc voir ce voisinage en étoile comme une extension du voisinage classique.  
La longueur de chaque branche (et donc son poid dans le calcul de U) dépend de la continuité des valeurs des pixels depuis s et de proche en proche sur la direction de la branche. Autrement dis, la longueur d'une branche est égale au nombre de pixels côte à côte suivant l'orientation de la branche, de même valeur (pour une image en noir et blanc), partant de s.  
Ainsi d'un pixel à l'autre on n'aura pas forcément un voisinage de même ampleur.  

Le poid d'une branche de voisinage est alors proportionel à sa longeur. On aurait:
$U_s=\beta x_s\sum_{i=1}^{4}{a_il_i} +\alpha x_s x_s^0$
avec $(l_i)$ les 8 lead et $(a_i)$ leur longueur.

On peut choisir une longueur maximale pour les branches, une majoration certaine étant la largeur de l'image. C'est d'ailleurs préférable d'un point de vue pratique car plus les branches sont longues plus les calcules le sont aussi.

L'algorithme de Vstar est simple: pour chaqun des voisins habituels de s (haut bas gauche droite), on regade son voisin opposé à s et sur la même direction (le "voisin du voisin"); s'il a la même valeur que le premier voisin, on l'intègre à la branche. Sinon la branche est terminée.

```{r Vstar}

Vstar=function(img, N, i, j, L){
  #fonction qui calcule le voisinage du pixel (i,j), selon le modèle de voisinage en étoile variable.
  
  vbranch=function(img, N, is, js, iv, jv, L){
	  #L détermine la longueur maximale d'une branche
	  #(iv, jv) appartient à [(0,1),(0,-1),(1,0),(-1,0)], c'est ce qui donne le sens de la branche à partir de s

	  v = c() #branche finale
	  vl = c() #branche brute
	  if(is<1 | is>N | js<1 | js>N){return("les coordonnées données sont en dehors de l'image")}

	  #----récupération des L sites de la branche potentielles sans condition----
	  for(k in(1:L)){
		  i <- is+k*iv
		  j <- js+k*jv
		  if(i>=1 && i<=N){ if(j>=1 && j<=N){ #teste si les coordonnées du candidat sont dans l'image
			  vl <- c(vl,img[i,j])
		  }}#if&if
	  }#for
	  if(is.null(vl[1])){return(0)} #si on est sur le bord
	
	  #----épuration selon la condition de valeur de site----
	  lead <- vl[1] #base de la branche, à côté du site
	  for(k in 1:length(vl)){ #parcours les L sites
		  if(vl[k]==lead){ v <- c(v,vl[k]) }#condition pour faire partie de la branche.
	  }#for
	
	  return(length(v)*lead) #"poid" de la branche. length(v) fait office de facteur, comme beta classiquement
  }#func
  
  #somme des quatre branches
	s <- 0
	s <- s + vbranch(img, N, i, j, -1, 0, L)
	s <- s + vbranch(img, N, i, j, 1, 0, L)
	s <- s + vbranch(img, N, i, j, 0, -1, L)
	s <- s + vbranch(img, N, i, j, 0, 1, L)
	return(s)
}#func
```


```{r recuitSimule_Vstar}
recuitSimule_Vstar=function(forme, N, p, B, beta, alpha, n, L){
	#fonction qui réalise l'algorithme de recuit, mais dont le calcul de voisinage se faite selon le modèle en étoile variable.
	
	#----image parfaite img0----
	img0 = imageGenerator(forme, N)
	
	#----image auxiliaire img1, avec bordure et bruitage----
	img1 = matrix(0, nrow=N+2, ncol=N+2)
	img1[2:(N+1),2:(N+1)] = bruiteur(img0, "rbinom", p)
	img2 = img1 #tampon
	img3 = img1 #bruit initiale

	for(k in 1:n){
	  
	  T <- 1/log(k+1)
	  
		#----choix d'un pixel au hasard----
		i <- 1+ceiling(N*runif(1))
		j <- 1+ceiling(N*runif(1))
		
		#----tirage nouvelle valeure candidate----
		img2[i,j] = -img1[i,j]
	
		#----voisinage selon le modèle en étoile----
	  v = Vstar(img1, N+2, i, j, L)
		
		#----potentiels----
		U1 = -B*img1[i,j]-img1[i,j]*(beta*v + alpha*img3[i,j])#potentiel actuel
		U2 = -B*img2[i,j]-img2[i,j]*(beta*v + alpha*img3[i,j])#potentiel candidat
	
		#----test----
		dU = U2-U1
		p <- exp(-dU/T)
		
		if(runif(1)<=p){img1[i,j]= -img1[i,j]}#changé
		else{img2[i,j] <- img1[i,j]} #inchangé
	}#for
	
	#----affichage----
	img3 <- img3[2:(N+1),2:(N+1)] #on retire le contour
	img1 <- img1[2:(N+1),2:(N+1)]
	
	par(mfrow=c(1,3))
	image(1:N,1:N,img0)#image initiale
	image(1:N+2,1:N+2,img3)#image  bruitée
	image(1:N+2,1:N+2,img1)#image restaurée
	
	return(correspondance(img0, img1, N))
  
}#func

```


# Amélioration de la rapidité des algorithmes

Depuis le début, on fixe le nombre d'itérations de l'algorithme (souvent à $10^4$ ou $10^5$). Cependant, il est très probable, de part l'avancé aléatoire de l'algorithme de recuit ou de métropolis, et d'autant plus du fait que les images à restaurer sont toutes différentes, que ce ne soit pas nécessaire de faire toujours le même nombre d'itérations pour arriver à restaurer comme on le souhaite.    
Une manière de rendre le nombre d'itérations variable est de le conditionner au nombre de parcours de site successifs sans changement de valeurs. En effet, si on ne change pas de valeur, c'est normalement parce que cette valeur était la bonne. Donc on introduit un paramètre S telle que, si on ne change plus de valeur S fois de suite, on supposera que l'image entière n'a plus à être modifié et on arrête l'algorithme.


Pour essayer la condition d'arrêt on modifie un petit peu recuitSimule() pour faire smartStop(). Etant donnée que c'est le nombre d'itérations qui nous interesse ici, on a retiré l'affichage des images.

```{r smartStop}
smartStop=function(forme, N, p, B, beta, alpha, S){
	#fonction qui réalise l'algorithme de recuit simulé avec pour condition d'arrêt faire S itérations successives sans changement de valeur.
	
	#----création de l'image parfaite img0----
	img0 = imageGenerator(forme, N)
	
	#----création d'une image auxiliaire img1, avec bord plus long et bruitage----
	img1 = matrix(0, nrow=N+2, ncol=N+2)
	img1[2:(N+1),2:(N+1)] = bruiteur(img0, "rbinom", p)
	img2 = img1 #image tampon
	img3 = img1 #mémoire du bruit initiale
	
  X<-0 #nombre d'itérations consécutives sans changement de spin
  it<-0 #compteur
  
  while(X<=S) { 
	  
    it <- it+1
	  T <- 1/log(it+1) #T tend vers 0
	  
		#----choix d'un pixel au hasard----
		i <- 1+ceiling(N*runif(1)) # indice entre 2 et N+1
		j <- 1+ceiling(N*runif(1))
		
		#----tirage nouvelle valeure candidate----
		img2[i,j] = -img1[i,j]
	
		#----voisinage----
	  v = Vstar(img1, N+2, i, j, 5) # L arbitrairement fixé à 5
		
		#----potentiels----
		U1 = -B*img1[i,j]-img1[i,j]*(beta*v + alpha*img3[i,j])#potentiel actuel
		U2 = -B*img2[i,j]-img2[i,j]*(beta*v + alpha*img3[i,j])#potentiel candidat
	
		#----test----
		dU = U2-U1
		p <- exp(-dU/T)
		
		if(runif(1)<=p){#on change la valeur du pixel
		  img1[i,j]= -img1[i,j]
		  X <- 0} #on a changé un pixel, retour à la case départ
		  
		else{
		  img2[i,j] <- img1[i,j]
		  X <- X+1} #on garde la valeur du pixel
	}#for
	
	#----RETURN----
	img1 <- img1[2:(N+1),2:(N+1)]
	corresp <- correspondance(img0, img1, N)
	return(c(corresp,it)) #(pourcentage de restauration, nombre d'itérations nécessaires)
  
}#func
```


Pour le test on va lancer plusieurs fois la fonction smartStop() avec des valeurs de S de plus en plus grandes et observer le pourcentage de restauration (grâce à correspondance()) associé. On utilise pour cela la fonction suivante:

```{r, disp_smartStop}
disp_smartStop=function(forme, N, p, B, beta, alpha, S, pas){
  
  plage = seq(pas,S,pas) #plage S des tirages successifs sans changement
  l = length(plage)
  corresp = c(1:l) #stock des pourcentages de restauration
  iter = c(1:l) #stock des quantités d'itérations
  
  for( ss in plage){
    result = smartStop(forme, N, p, B, beta, alpha, ss)
    corresp[ss/pas] <- result[1]
    iter[ss/pas] <- result[2]

  }#for
  
  rev <- data.frame(plage_evaluation=plage, correspondance=corresp, nombre_iteration=iter )

  ggplot(data = rev, aes(x="largeur de la plage S",y="nombre d'itération n"))+geom_line()+geom_point() 
    # + geom_smooth()  
  print(rev)
}#func
```

On fait le test en partant d'une condition à 200 itérations successive, jusqu'à 2000 itérations successives, par pas de 200:

```{r, test_disp_smartStop}
disp_smartStop("rectangle", 64, 0.25, 0, 0.66, 0.33, 2000, 200)
```

On remarque deux choses:    
- la première c'est que finalement on obtient un pourcentage de restauration déjà de 99% dès $S>=600$, et qu'en suite même avec S deux ou trois fois plus grand on ne parvient pas a beaucoup améliorer ce résultat, seulement au dixième.  
- la seconde, et c'est elle qui nous indique la pertinence de cette condition d'arrêt, c'est qu'en augmentant la condition d'arrêt de 1200 à 1400 itérations successives sans changement, et aussi de 1600 à 2000, on a une diminution du nombre totale d'itération. Si on avait du choisir arbitrairement n pour S=1800 en connaissant les résultats à S=1600, on aurait logiquement choisis n plus grand puisque la condition est plus dure. Mais là on voit bien que parfois le hasard fait que la condition est remplie relativement plus rapidement que la tendence le suppose.    

Pour alléger encore davantage la condition d'arrêt et réduire le nombre d'itérations, on peut ajouter une variable de pourcentage d'erreur tolérée prcm; sur les S itérations successives, si on obtient entre 0 et prcm*S changements ($0<prcm<1$), la condition d'arrêt est quand même validée. S'il y a davantage de changements sur les S itérations, la condition n'est pas remplie et l'algorithme continue.

```{r smartStopLight}
smartStopLight=function(forme, N, p, B, beta, alpha, S, prcm){

	img0 = imageGenerator(forme, N)
	img1 = matrix(0, nrow=N+2, ncol=N+2)
	img1[2:(N+1),2:(N+1)] = bruiteur(img0, "rbinom", p)
	img2 = img1 #image tampon
	img3 = img1 #mémoire du bruit initiale
  X<-0 #nombre d'itérations consécutives sans changement de spin
  Y <- 0 #nombre de changements de spin, remis à 0 dès que Y==m.
  m <- prcm*S #nombre d'erreurs tolérées
  it<-0 #compteur d'itération général
  while(X<=S) { 
    it <- it+1
	  T <- 1/log(it+1) #T tend vers 0
		i <- 1+ceiling(N*runif(1)) # indice entre 2 et N+1
		j <- 1+ceiling(N*runif(1))
		img2[i,j] = -img1[i,j]
	  v = Vstar(img1, N+2, i, j, 5) # L arbitrairement fixé à 5
		U1 = -B*img1[i,j]-img1[i,j]*(beta*v + alpha*img3[i,j])#potentiel actuel
		U2 = -B*img2[i,j]-img2[i,j]*(beta*v + alpha*img3[i,j])#potentiel candidat
		dU = U2-U1
		p <- exp(-dU/T)
		if(runif(1)<=p){#on change la valeur du pixel
		  img1[i,j]= -img1[i,j]
		  Y <- Y+1
		  if(Y==m+1){ #dépassement du cota de changement de valeur m
		    X <- 0
		    Y <- 0}
		  else{X <- X+1}
		}#if 
		else{ #on garde la valeur du pixel
		  img2[i,j] <- img1[i,j]
		  X <- X+1} 
	}#for
	
	#----RETURN----
	img1 <- img1[2:(N+1),2:(N+1)]
	corresp <- correspondance(img0, img1, N)
	return(c(corresp,it)) #(pourcentage de restauration, nombre d'itérations nécessaires)
}#func

#smartStopLight("rectangle", 64,0.25, 0, 2/3, 1/3, 500, 15)
```

On réalise le test du code de la même manière que pour smartStop(), avec les même valeurs, en choisissant $prcm=1\%$.

```{r disp_smartStopLight}
disp_smartStopLight=function(forme, N, p, B, beta, alpha, S, pas, prcm){
  
  plage = seq(pas,S,pas) #plage S des tirages successifs sans changement
  l = length(plage)
  error = c(1:l) #stock du nombre d'erreurs maximal accepté
  corresp = c(1:l) #stock des pourcentages de restauration
  iter = c(1:l) #stock des quantités d'itérations
  
  for( ss in plage){
    #m = prcm*ss
    result = smartStopLight(forme, N, p, B, beta, alpha, ss, prcm)
    error[ss/pas] <- prcm*ss #nombre d'erreurs tolérées 
    corresp[ss/pas] <- result[1]
    iter[ss/pas] <- result[2]

  }#for
  
  rev <- data.frame(plage_evaluation=plage, correspondance=corresp, nombre_iteration=iter, erreur_maximal=error)

  ggplot(data = rev, aes(x="largeur de la plage",y="nombre d'itération"))+geom_line()+geom_point() 
    # + geom_smooth()  
  print(rev)
}#func
```


```{r, test_disp_smartStopLight}
disp_smartStopLight("rectangle", 64, 0.25, 0, 0.66, 0.33, 2000, 200, 0.01)
```

On peut déjà dire que le nombre total d'itérations a bien chuté par rapport au test précédent (qui revenait finalement à choisir prcm=0). On ne dépasse pas la barre des 15000, alors que pour prcm=0 on était monté jusqu'à 30000!    
Au niveau des performances on ne perd presque pas, ce qui valide l'introduction d'un parametre d'erreur. Par contre on observe qu'il faut davantage augmenter S pour atteindre les 99% de restauration (1200 ici contre 600 à prcm=0).


A terme on aimerait pouvoir déterminer a priori, étant donnée l'image bruitée, le nombre minimal d'itérations successives sans modification à réaliser pour une restauration à un certain pourcentage.

## Algorithme d'ICM

Un algorithme de restauration plus rapide que celui d'Ising, Metroppolis ou de recuit simulé, est l'algorithme d'ICM. Il est très similaire à l'algorithme de Metropolis, si ce n'est que l'on n'autorise pas de remonté d'énergie. Concrètement à chaque itération, on choisira systématiquement dans E la valeur pour $X_s$ la plus probable, soit la valeur amenant s à la plus faible énergie entre les deux valeurs (avec Metropolis, on autorisait quand même un changement pour un $x_s$ de plus haute énergie, avec pour probabilité l'esponetiel de la variation d'énergie).


On reprend l'algorithme de Metropolis en modifiant la partie de test:

```{r, ICM}
ICM=function(forme, N, p, B, beta, alpha, n){
	#fonction qui réalise l'algorithme d'ICM, pour restaurer img1
	
	#----création de l'image parfaite img0----
	img0 = imageGenerator(forme, N)
	
	#----création d'une image auxiliaire img1, avec bordure et bruit----
	img1 = matrix(0, nrow=N+2, ncol=N+2)
	img1[2:(N+1),2:(N+1)] = bruiteur(img0, "rbinom", p)
	img2 = img1 #image tampon
	img3 = img1 #mémoire du bruit initiale

	for(k in 1:n){ #n visites de pixels
	  
		#----choix d'un pixel au hasard----
		i <- 1+ceiling(N*runif(1)) # indice entre 2 et N+1
		j <- 1+ceiling(N*runif(1))
		
		#----tirage nouvelle valeure candidate----
		img2[i,j] = -img1[i,j]
	
		#----voisinage----
		v = img1[i+1,j] + img1[i-1,j] + img1[i,j+1] + img1[i,j-1]
	
		#----potentiels----
		U1 = -B*img1[i,j]-img1[i,j]*(beta*v + alpha*img3[i,j])#potentiel actuel
		U2 = -B*img2[i,j]-img2[i,j]*(beta*v + alpha*img3[i,j])#potentiel candidat
	
		#----probabilité conditionnelle locale, "recuite" à chaque itération----
		
		if(U1>U2){img1[i,j]= -img1[i,j]}#le changement proposé fait diminuer le potentiel local, on l'accept
		else{img2[i,j] <- img1[i,j]} #le changement proposé fait augmenter le potentiel local, on le refuse
	}#for
	
	#----affichage----
	img3 <- img3[2:(N+1),2:(N+1)] #retire le contour
	img1 <- img1[2:(N+1),2:(N+1)]
	
	return(correspondance(img0,img1,N))
  
}#func
```


```{r, RETURN_metropolisIsing, include=FALSE}
metropolisIsing_return=function(forme, N, p, B, beta, alpha, n){
	#MEtropolisIsing sans affichage d'image, pour le test de vitesse
	
	#----création de l'image parfaite img0----
	img0 = imageGenerator(forme, N)
	
	#----création d'une image auxiliaire img1, avec bord plus long et bruitage----
	img1 = matrix(0, nrow=N+2, ncol=N+2)
	img1[2:(N+1),2:(N+1)] = bruiteur(img0, "rbinom", p)
	img2 = img1 #image tampon
	img3 = img1 #mémoire du bruit initiale

	for(k in 1:n){ #n visites de pixels
	
		#----choix d'un pixel au hasard----
		i <- 1+ceiling(N*runif(1)) # indice entre 2 et N+1
		j <- 1+ceiling(N*runif(1))
		
		#----tirage nouvelle valeure candidate----
		img2[i,j] = -img1[i,j]
	
		#----voisinage----
		v = img1[i+1,j] + img1[i-1,j] + img1[i,j+1] + img1[i,j-1]
	
		#----potentiels----
		U1 = -B*img1[i,j]-img1[i,j]*(beta*v + alpha*img3[i,j])#potentiel actuel
		U2 = -B*img2[i,j]-img2[i,j]*(beta*v + alpha*img3[i,j])#potentiel candidat
	
		#----proba conditionnelle locale----
		dU = U2-U1
		p <- exp(-dU)
		
		if(runif(1)<=p){img1[i,j]= -img1[i,j]}#on change la valeur du pixel
		else{img2[i,j] <- img1[i,j]} #on garde la valeur du pixel
	}#for
	
	#----affichage----
	img3 <- img3[2:(N+1),2:(N+1)] #on retire le contour
	img1 <- img1[2:(N+1),2:(N+1)]
	
	return(correspondance(img0,img1,N))
  
}#func
```

```{r, RETURN_recuiSimule, include=FALSE}
recuitSimule_return=function(forme, N, p, B, beta, alpha, n){
	#fonction qui réalise l'algorithme de recuit simulé, pour restaurer img1
	
	#----création de l'image parfaite img0----
	img0 = imageGenerator(forme, N)
	
	#----création d'une image auxiliaire img1, avec bordure et bruit----
	img1 = matrix(0, nrow=N+2, ncol=N+2)
	img1[2:(N+1),2:(N+1)] = bruiteur(img0, "rbinom", p)
	img2 = img1 #image tampon
	img3 = img1 #mémoire du bruit initiale

	for(k in 1:n){ #n visites de pixels
	  
	  T <- 1/log(k+1) #T tend lentement vers 0
	  
		#----choix d'un pixel au hasard----
		i <- 1+ceiling(N*runif(1)) # indice entre 2 et N+1
		j <- 1+ceiling(N*runif(1))
		
		#----tirage nouvelle valeure candidate----
		img2[i,j] = -img1[i,j]
	
		#----voisinage----
		v = img1[i+1,j] + img1[i-1,j] + img1[i,j+1] + img1[i,j-1]
	
		#----potentiels----
		U1 = -B*img1[i,j]-img1[i,j]*(beta*v + alpha*img3[i,j])#potentiel actuel
		U2 = -B*img2[i,j]-img2[i,j]*(beta*v + alpha*img3[i,j])#potentiel candidat
	
		#----probabilité conditionnelle locale, "recuite" à chaque itération----
		dU = U2-U1
		p <- exp(-dU/T)
		
		if(runif(1)<=p){img1[i,j]= -img1[i,j]}#changement
		else{img2[i,j] <- img1[i,j]} #inchangé
	}#for
	
	#----affichage----
	img3 <- img3[2:(N+1),2:(N+1)] #retire le contour
	img1 <- img1[2:(N+1),2:(N+1)]
	
	return(correspondance(img0,img1,N))
  
}#func
```




```{r, disp_GeneralspeedTest}
disp_generalSpeedTest=function(forme, N, p, B, beta, alpha, nn, pas){
  
  iteration = seq(pas,nn,pas) #plage S des tirages successifs sans changement
  l = length(iteration) #nombre de test que l'on va réaliser
  corresp_metro = c(1:l) #stock des pourcentages de restauration pour Metropolis
  corresp_ICM = c(1:l) #stock des pourcentages de restauration pour ICM
  corresp_recuit = c(1:l) #// pour le recuit simulé
  
  for( n in iteration){
    corresp_metro[n/pas] <- metropolisIsing_return(forme, N, p, B, beta, alpha, n)
    corresp_recuit[n/pas] <- recuitSimule_return(forme, N, p, B, beta, alpha, n)
    corresp_ICM[n/pas] <- ICM(forme, N, p, B, beta, alpha, n)
  }#for
  
  rev <- data.frame(nombre_iteration=iteration, restauration_Metropolis=corresp_metro, restauration_recuit=corresp_recuit, restauration_ICM=corresp_ICM)

  ggplot(data = rev, aes(x="largeur de la plage",y="nombre d'itération"))+geom_line()+geom_point() 
    # + geom_smooth()  
  print(rev)
}#func
```


```{r}
disp_generalSpeedTest("rectangle",64,0.25,0,0.66,0.33,10^5,10^4)
```

Les résultats montrent bien que l'algorithme d'ICM converge plus vite vers la configuration de plus faible énergie, donc restaure plus rapidement, que ses deux homologues.


# Evolution de la restauration en fonction d'un nombre d'itérations

Avec des algorithmes dont le nombre d'itération varie, on peut se demander quelle est la probabilité d'avoir une image restaurée à un H%, après n itérations consécutives sans changements.


Une première majoration très grossière peut être de considérer l'ensemble des images de plus hautes énergie, et de déterminer combien d'itération il faut au minimum pour les ramener à l'image blanche. Ce nombre sera forcément supérieur ou égale au nombre d'itérations nécessaires pour n'importe quel image donnée de même taille. 

## Probabilité d'avoir la configuration d'énergie minimale 

### Estimation du nombre de parcours minimum nécessaires à la restauration d'une image pour toute image donnée
Une première majoration très grossière peut se faire en passant l'image de départ à restaurer comme variable, pour laquelle nous n'avons à priori aucune informations. Peut importe l'image à restaurer, combien de parcours de site l'algorithme doit-il réaliser ?  

Pour un voisinage classique avec 4 voisins prenna valeur dans $\{-1,1\}$, on a $2^4=16$ configurations de voisinages possibles.  

L'avantage de notre approche, c'est qu'en l'absence d'information sur l'image à restaurer, on peut raisonnable considérer ces 16 configurations de voisinage comme équiprobables.

D'un point de vu énergétique, il n'y a que 5 cas possibles. $V_s\in\{-4,\ -2,\ 0,\ 2,\ 4\}$.


### Probabilité de succès pour un pixel
### Probabilité de succès pour une configuration complète

## Probabilité d'avoir restauré l'image à H%
